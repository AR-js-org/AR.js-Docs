{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AR.js - Augmented Reality on the Web AR.js is a lightweight library for Augmented Reality on the Web, coming with features like Image Tracking, Location based AR and Marker tracking. What Web AR means (Augmented Reality on the Web) Augmented Reality is the technology that makes possible to add overlayed content on the real world. It can be provided for several type of devices: handleheld (like mobile phones), headsets, desktop displays, and so on. For handleheld devices (more in general, for video-see-through devices) the 'reality' is captured from one or more cameras and then shown on the device display, adding some kind of content on top of it. For developers, to develop Augmented Reality ('AR' from now on) on the Web, means to void all the Mobile app developement efforts and costs related to App stores (validation, time to publish). It also means to re-use well known technologies like Javascript, HTML and CSS, known from a lot of developers and possibly designers. It basically means that is possible to release every new version instantly, fix bugs or release new features in near real-time, opening a lot of pratical possibilities. For users, it means to reach an AR experience just visiting a website. As QR Codes are now widespread, it's also possible to scan a QR Code and reach the URL without even type. Addictionally, users do not have to reserve storage space on their download the AR app, and do not have to keep it updated. Why AR.js We believe in the Web, as a collaborative and accessible environment. We also believe in the Augmented Reality technology, as a new communication medium, that can help people to see the reality in new, exciting ways. We see Augmented Reality (AR) used everyday for a lot of useful applications, from art, to education, also for fun. We strongly believe that such a powerful technology, that can help people and leverage their creativity, should be free in some way. Also collaborative, if possible. And so, we continue the work started by Jerome Etienne, in bringing AR on the Web, as a free and Open Source technology. Thank you for being interested in this, if you'd like to collaborate in any way, contact us ( https://twitter.com/nicolocarp ). The project is now under a Github organization, that you can find at https://github.com/ar-js-org and you can ask to be part of it, for free. AR types AR.js features the following types of Augmented Reality, on the Web: Image Tracking , when a 2D images is found by the camera, it's possible to show some kind of content on top of it, or near it. The content can be a 2D image, a GIF, a 3D model (also animated) and a 2D video too. Cases of use: Augmented Art, learning (Augmented books), Augmented flyers, advertising, etc. Location Based AR , this kind of AR uses real-world places in order to show Augmented Reality content, on the user device. The experiences that can be built with this library are those that uses users position in the real world. The user can move (ideally outdoor) and through their smartphones they can see AR content where places are in the real world. Moving around and rotating the phone will make the AR content change according to users position and rotation (so places are 'sticked' in their real position, and appear bigger/thinner according to their distance from the user). With this solution it\u2019s possible to build experiences like interactive support for touristic guides, support when exploring a new city, find places of interest like buildings, museums, restaurants, hotels and so on. It\u2019s also possible to build learning experiences like treasure hunts and biology or history learning games, or use this technology for situated art (visual art experiences bound to specific real world coordinates). Marker Tracking , When a marker is found by the camera, it's possible to show some content (same as Image Tracking). Markers are very stable but limited in shape, color and size. It is suggested for those experiences where are required a lot of different markers with different content. Examples of use: (Augmented books), Augmented flyers, advertising. Key points Very Fast : It runs efficiently even on phones Web-based : It is a pure web solution, so no installation required. Full javascript based on three.js + A-Frame + jsartoolkit5 Open Source : It is completely open source and free of charge! Standards : It works on any phone with webgl and webrtc AR.js has reached version 3. This is the official repository: https://github.com/AR-js-org/AR.js . If you want to visit the old AR.js repository, here it is: https://github.com/jeromeetienne/AR.js . Import the library AR.js from version 3 has a new structure. AR.js is coming in two, different build. They are both maintained. They are exclusive. The file you want to import depends on what features you want, and also which render library you want to use (A-Frame or three.js). AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . You can import AR.js in one version of your choice, using the script tag on your HTML. AR.js with Image Tracking + Location Based AR Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar-nft.js AR.js with Marker Tracking + Location Based AR: Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar.js If you want to import a specific version, you can do that easily replacing master with the version tag, e.g.: script src= https://raw.githack.com/AR-js-org/AR.js/3.0.0/aframe/build/aframe-ar-nft.js Requirements Some requirements and known restrictions are listed below: It works on every phone with webgl and webrtc . Marker based is very lightweight, while Image Tracking is more CPU consuming You cannot use Chrome on iOS, as Chrome on iOS did not support, at the moment, camera access On device with multi-cameras, Chrome may have problems on detecting the right one. Please use Firefox if you find that AR.js opens on the wrong camera. There is an open issue for this. To work with Location Based feature, your phone needs to have GPS sensors Please, read carefully any suggestions that AR.js pops-up -as alerts- for Location Based on iOS, as iOS requires user actions to activate geoposition Location Based feature is only available on A-Frame Always deploy under https Accessing to the phone camera or to camera GPS sensors, due to major browsers restrictions, can be done only under https websites. All the examples you will see, and all AR.js web apps in general, have to be run on a server. You can use local server or deploy the static web app on the web. So don't forget to always run your examples on secure connections servers or localhost. Github Pages is a great way to have free and live websites under https. Getting started Here we present three, basic examples, one for each AR feature. For specific documentation, on the top menu you can find every section, or you can click on the following links: Image Tracking Documentation Location Based Documentation Marker Based Documentation Image Tracking Example There is a Codepen for you to try. Below you can find also a live example. Please follow these simple steps: Create a new project with the code below (or open this live example and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded -- div class= arjs-loader div Loading, please wait... /div /div a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors proxy to avoid cross-origin problems -- a-nft type= nft url= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 a-entity gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf scale= 5 5 5 position= 50 150 0 /a-entity /a-nft a-entity camera /a-entity /a-scene /body Location Based Example Try it live with this Codepen . It retrieves your position and places a text near you. Please follow these simple steps: Create a new project with the following snippet, and change add-your-latitude and add-your-longitude with your latitude and longitude, without the . Run it on a server Activate GPS on your phone and navigate to the example URL Look around. You should see the text looking at you, appearing in the requested position, even if you look around and move the phone. !DOCTYPE html html head meta charset= utf-8 / meta http-equiv= X-UA-Compatible content= IE=edge / title GeoAR.js demo /title script src= https://aframe.io/releases/1.0.4/aframe.min.js /script script src= https://unpkg.com/aframe-look-at-component@0.8.0/dist/aframe-look-at-component.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script /head body style= margin: 0; overflow: hidden; a-scene vr-mode-ui= enabled: false embedded arjs= sourceType: webcam; debugUIEnabled: false; a-text value= This content will always face you. look-at= [gps-camera] scale= 120 120 120 gps-entity-place= latitude: add-your-latitude ; longitude: add-your-longitude ; /a-text a-camera gps-camera rotation-reader /a-camera /a-scene /body /html Marker Based Example Please follow these simple steps: Create a new project with the code below (or open this live example and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. !DOCTYPE html html script src= https://aframe.io/releases/1.0.4/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html Advanced stuff AR.js offers two ways, with A-Frame, to interact with the web page: to interact directly with AR content and Overlayed DOM interaction. Also, there are several Custom Events triggered during the life cycle of every AR.js web app. You can learn more about these aspects on the UI and Events section . AR.js architecture AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . three.js folder contains source code for AR.js core, Marker based and Image Tracking examples for AR.js three.js based build for three.js AR.js based vendor stuff (jsartoolkit5) workers (used for Image Tracking). When you find files that ends with -nft suffix, they're boundled only with the Image Tracking version. A-Frame version of AR.js uses three.js parts as its core. A-Frame code, on AR.js, is simply a wrapper to write AR with Custom Components in HTML. aframe folder contains source code for AR.js A-Frame (aka wrappers for Marker Based, Image Tracking components) source code for Location Based build for A-Frame AR.js based examples for A-Frame AR.js. Troubleshooting, feature requests, community You can find a lot of help on the old AR.js repositories issues . Please search on open/closed issues, you may find a interesting stuff. Contributing From opening a bug report to creating a pull request: every contribution is appreciated and welcome. If you're planning to implement a new feature or change the api please create an issue first. This way we can ensure that your precious work is not in vain. Issues If you are having configuration or setup problems, please post a question to StackOverflow . You can also address question to us in our Gitter chatroom If you have discovered a bug or have a feature suggestion, feel free to create an issue on Github. Submitting Changes After getting some feedback, push to your fork and submit a pull request. We may suggest some changes or improvements or alternatives, but for small changes your pull request should be accepted quickly. Some things that will increase the chance that your pull request is accepted: Follow the existing coding style Write a good commit message","title":"Home"},{"location":"#arjs-augmented-reality-on-the-web","text":"AR.js is a lightweight library for Augmented Reality on the Web, coming with features like Image Tracking, Location based AR and Marker tracking.","title":"AR.js - Augmented Reality on the Web"},{"location":"#what-web-ar-means-augmented-reality-on-the-web","text":"Augmented Reality is the technology that makes possible to add overlayed content on the real world. It can be provided for several type of devices: handleheld (like mobile phones), headsets, desktop displays, and so on. For handleheld devices (more in general, for video-see-through devices) the 'reality' is captured from one or more cameras and then shown on the device display, adding some kind of content on top of it. For developers, to develop Augmented Reality ('AR' from now on) on the Web, means to void all the Mobile app developement efforts and costs related to App stores (validation, time to publish). It also means to re-use well known technologies like Javascript, HTML and CSS, known from a lot of developers and possibly designers. It basically means that is possible to release every new version instantly, fix bugs or release new features in near real-time, opening a lot of pratical possibilities. For users, it means to reach an AR experience just visiting a website. As QR Codes are now widespread, it's also possible to scan a QR Code and reach the URL without even type. Addictionally, users do not have to reserve storage space on their download the AR app, and do not have to keep it updated.","title":"What Web AR means (Augmented Reality on the Web)"},{"location":"#why-arjs","text":"We believe in the Web, as a collaborative and accessible environment. We also believe in the Augmented Reality technology, as a new communication medium, that can help people to see the reality in new, exciting ways. We see Augmented Reality (AR) used everyday for a lot of useful applications, from art, to education, also for fun. We strongly believe that such a powerful technology, that can help people and leverage their creativity, should be free in some way. Also collaborative, if possible. And so, we continue the work started by Jerome Etienne, in bringing AR on the Web, as a free and Open Source technology. Thank you for being interested in this, if you'd like to collaborate in any way, contact us ( https://twitter.com/nicolocarp ). The project is now under a Github organization, that you can find at https://github.com/ar-js-org and you can ask to be part of it, for free.","title":"Why AR.js"},{"location":"#ar-types","text":"AR.js features the following types of Augmented Reality, on the Web: Image Tracking , when a 2D images is found by the camera, it's possible to show some kind of content on top of it, or near it. The content can be a 2D image, a GIF, a 3D model (also animated) and a 2D video too. Cases of use: Augmented Art, learning (Augmented books), Augmented flyers, advertising, etc. Location Based AR , this kind of AR uses real-world places in order to show Augmented Reality content, on the user device. The experiences that can be built with this library are those that uses users position in the real world. The user can move (ideally outdoor) and through their smartphones they can see AR content where places are in the real world. Moving around and rotating the phone will make the AR content change according to users position and rotation (so places are 'sticked' in their real position, and appear bigger/thinner according to their distance from the user). With this solution it\u2019s possible to build experiences like interactive support for touristic guides, support when exploring a new city, find places of interest like buildings, museums, restaurants, hotels and so on. It\u2019s also possible to build learning experiences like treasure hunts and biology or history learning games, or use this technology for situated art (visual art experiences bound to specific real world coordinates). Marker Tracking , When a marker is found by the camera, it's possible to show some content (same as Image Tracking). Markers are very stable but limited in shape, color and size. It is suggested for those experiences where are required a lot of different markers with different content. Examples of use: (Augmented books), Augmented flyers, advertising.","title":"AR types"},{"location":"#key-points","text":"Very Fast : It runs efficiently even on phones Web-based : It is a pure web solution, so no installation required. Full javascript based on three.js + A-Frame + jsartoolkit5 Open Source : It is completely open source and free of charge! Standards : It works on any phone with webgl and webrtc AR.js has reached version 3. This is the official repository: https://github.com/AR-js-org/AR.js . If you want to visit the old AR.js repository, here it is: https://github.com/jeromeetienne/AR.js .","title":"Key points"},{"location":"#import-the-library","text":"AR.js from version 3 has a new structure. AR.js is coming in two, different build. They are both maintained. They are exclusive. The file you want to import depends on what features you want, and also which render library you want to use (A-Frame or three.js). AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . You can import AR.js in one version of your choice, using the script tag on your HTML. AR.js with Image Tracking + Location Based AR Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar-nft.js AR.js with Marker Tracking + Location Based AR: Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar.js If you want to import a specific version, you can do that easily replacing master with the version tag, e.g.: script src= https://raw.githack.com/AR-js-org/AR.js/3.0.0/aframe/build/aframe-ar-nft.js","title":"Import the library"},{"location":"#requirements","text":"Some requirements and known restrictions are listed below: It works on every phone with webgl and webrtc . Marker based is very lightweight, while Image Tracking is more CPU consuming You cannot use Chrome on iOS, as Chrome on iOS did not support, at the moment, camera access On device with multi-cameras, Chrome may have problems on detecting the right one. Please use Firefox if you find that AR.js opens on the wrong camera. There is an open issue for this. To work with Location Based feature, your phone needs to have GPS sensors Please, read carefully any suggestions that AR.js pops-up -as alerts- for Location Based on iOS, as iOS requires user actions to activate geoposition Location Based feature is only available on A-Frame","title":"Requirements"},{"location":"#always-deploy-under-https","text":"Accessing to the phone camera or to camera GPS sensors, due to major browsers restrictions, can be done only under https websites. All the examples you will see, and all AR.js web apps in general, have to be run on a server. You can use local server or deploy the static web app on the web. So don't forget to always run your examples on secure connections servers or localhost. Github Pages is a great way to have free and live websites under https.","title":"Always deploy under https"},{"location":"#getting-started","text":"Here we present three, basic examples, one for each AR feature. For specific documentation, on the top menu you can find every section, or you can click on the following links: Image Tracking Documentation Location Based Documentation Marker Based Documentation","title":"Getting started"},{"location":"#image-tracking-example","text":"There is a Codepen for you to try. Below you can find also a live example. Please follow these simple steps: Create a new project with the code below (or open this live example and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded -- div class= arjs-loader div Loading, please wait... /div /div a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors proxy to avoid cross-origin problems -- a-nft type= nft url= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 a-entity gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf scale= 5 5 5 position= 50 150 0 /a-entity /a-nft a-entity camera /a-entity /a-scene /body","title":"Image Tracking Example"},{"location":"#location-based-example","text":"Try it live with this Codepen . It retrieves your position and places a text near you. Please follow these simple steps: Create a new project with the following snippet, and change add-your-latitude and add-your-longitude with your latitude and longitude, without the . Run it on a server Activate GPS on your phone and navigate to the example URL Look around. You should see the text looking at you, appearing in the requested position, even if you look around and move the phone. !DOCTYPE html html head meta charset= utf-8 / meta http-equiv= X-UA-Compatible content= IE=edge / title GeoAR.js demo /title script src= https://aframe.io/releases/1.0.4/aframe.min.js /script script src= https://unpkg.com/aframe-look-at-component@0.8.0/dist/aframe-look-at-component.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script /head body style= margin: 0; overflow: hidden; a-scene vr-mode-ui= enabled: false embedded arjs= sourceType: webcam; debugUIEnabled: false; a-text value= This content will always face you. look-at= [gps-camera] scale= 120 120 120 gps-entity-place= latitude: add-your-latitude ; longitude: add-your-longitude ; /a-text a-camera gps-camera rotation-reader /a-camera /a-scene /body /html","title":"Location Based Example"},{"location":"#marker-based-example","text":"Please follow these simple steps: Create a new project with the code below (or open this live example and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. !DOCTYPE html html script src= https://aframe.io/releases/1.0.4/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html","title":"Marker Based Example"},{"location":"#advanced-stuff","text":"AR.js offers two ways, with A-Frame, to interact with the web page: to interact directly with AR content and Overlayed DOM interaction. Also, there are several Custom Events triggered during the life cycle of every AR.js web app. You can learn more about these aspects on the UI and Events section .","title":"Advanced stuff"},{"location":"#arjs-architecture","text":"AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . three.js folder contains source code for AR.js core, Marker based and Image Tracking examples for AR.js three.js based build for three.js AR.js based vendor stuff (jsartoolkit5) workers (used for Image Tracking). When you find files that ends with -nft suffix, they're boundled only with the Image Tracking version. A-Frame version of AR.js uses three.js parts as its core. A-Frame code, on AR.js, is simply a wrapper to write AR with Custom Components in HTML. aframe folder contains source code for AR.js A-Frame (aka wrappers for Marker Based, Image Tracking components) source code for Location Based build for A-Frame AR.js based examples for A-Frame AR.js.","title":"AR.js architecture"},{"location":"#troubleshooting-feature-requests-community","text":"You can find a lot of help on the old AR.js repositories issues . Please search on open/closed issues, you may find a interesting stuff.","title":"Troubleshooting, feature requests, community"},{"location":"#contributing","text":"From opening a bug report to creating a pull request: every contribution is appreciated and welcome. If you're planning to implement a new feature or change the api please create an issue first. This way we can ensure that your precious work is not in vain.","title":"Contributing"},{"location":"#issues","text":"If you are having configuration or setup problems, please post a question to StackOverflow . You can also address question to us in our Gitter chatroom If you have discovered a bug or have a feature suggestion, feel free to create an issue on Github.","title":"Issues"},{"location":"#submitting-changes","text":"After getting some feedback, push to your fork and submit a pull request. We may suggest some changes or improvements or alternatives, but for small changes your pull request should be accepted quickly. Some things that will increase the chance that your pull request is accepted: Follow the existing coding style Write a good commit message","title":"Submitting Changes"},{"location":"about/","text":"Aknowledgments This project has been created by @jeromeetienne and it is now maintained by @nicolocarpignoli and the AR.js Org Community. Notes about AR.js 3 release: After months of work, we have changed AR.js for good. The aim was to make it a true, free alternative to paid Web AR solutions. We don't know if we're already there, but now the path is clear, at least. We have worked hard, spent many days and nights\u200a-\u200aobviously, we are coders, what did you expect?\u200a-\u200aand we are now so thrilled to share this achievement with the community. We know that it can be better, we know its limitations, but we would love to share this journey's result. AR.js is now under a Github organisation, that means, more collaborative than ever. It has a new structure, and a lot of new code. And most of all, we've added Image Tracking, what we felt was the missing piece for a true alternative to Web AR. A huge, huge thanks to the wonderful guys who made this possible: Walter Perdan Thorsten Bux Daniel Fernandes misdake hatsumatsu and many more. It was great to built this with all of you.","title":"About"},{"location":"about/#aknowledgments","text":"This project has been created by @jeromeetienne and it is now maintained by @nicolocarpignoli and the AR.js Org Community. Notes about AR.js 3 release: After months of work, we have changed AR.js for good. The aim was to make it a true, free alternative to paid Web AR solutions. We don't know if we're already there, but now the path is clear, at least. We have worked hard, spent many days and nights\u200a-\u200aobviously, we are coders, what did you expect?\u200a-\u200aand we are now so thrilled to share this achievement with the community. We know that it can be better, we know its limitations, but we would love to share this journey's result. AR.js is now under a Github organisation, that means, more collaborative than ever. It has a new structure, and a lot of new code. And most of all, we've added Image Tracking, what we felt was the missing piece for a true alternative to Web AR. A huge, huge thanks to the wonderful guys who made this possible: Walter Perdan Thorsten Bux Daniel Fernandes misdake hatsumatsu and many more. It was great to built this with all of you.","title":"Aknowledgments"},{"location":"image-tracking/","text":"Image Tracking Image Tracking makes possible to scan a picture, a drawing, any image, and show content over it. All the following examples are with A-Frame, for semplicity. You can use three.js if you want. See on the official repository the nft three.js example . All A-Frame examples for Image Tracking can be found here . Getting started with Image Tracking Natural Feature Tracking or NFT is a technology that enables the use of images instead of markers like QR Codes or the Hiro marker. The software tracks interesting points in the image and using them, it estimates the position of the camera. These interesting points (aka \"Image Descriptors\") are created using the NFT Marker Creator , a tool available for creating NFT markers. It comes in two versions: the Web version (recommended), and the node.js version . There is also a fork of this project on the AR.js Github organisation, but as for now, Daniel Fernandes version works perfectly. Thanks to Daniel Fernandes for contribution on this docs section. Choose good images If you want to understand the creation of markers in more depth, check out the NFT Marker Creator wiki . It explains also why certain images work way better than others. An important factor is the DPI of the image: a good dpi (300 or more) will give a very good stabilization, while low DPI (like 72) will require the user to stay very still and close to the image, otherwise tracking will lag. Create Image Descriptors Once you have chosen your image, you can either use the NFT Marker Creator in its Web version or the node version. If you're using the node version, this is the basic command to run: node app.js -i path-to-the-img/image-name.jpg/png After that, you will find the Image Descriptors files on the output folder. In the web version, the generator will automatically download the files from your browser. In either cases, you will end up with three files as Image Descriptors, with .fset , .fset3 , .iset . Each of them will have the same prefix before the file extension. That one will be the Image Descriptor name that you will use on the AR.js web app. For example: with files trex.fset , trex.fset3 and trex.iset , your Image Descriptors name will be trex . Render the content Now it's time to create the actual AR web app. !-- import aframe and then ar.js with image tracking / location based features -- script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script !-- style for the loader -- style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -- div class= arjs-loader div Loading, please wait... /div /div !-- a-frame scene -- a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- a-nft is the anchor that defines an Image Tracking entity -- !-- on 'url' use the path to the Image Descriptors created before. -- !-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -- a-nft type= nft url= path-to-your-image-descriptors smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 !-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -- a-entity gltf-model= path-to-your-model scale= 5 5 5 position= 50 150 0 /a-entity /a-nft !-- static camera that moves according to the device movemenents -- a-entity camera /a-entity /a-scene /body See on the comments above, inline on the code, for explanations. You can refer to A-Frame docs to know everything about content and customization. You can add geometries, 3D models, videos, images. And you can customize their position, scale, rotation and so on. The only custom component here is the a-nft , the Image Tracking HTML anchor. a-nft\\ Here are the attributes for this entity Attribute Description Component Mapping type type of marker - ['nft' only valid value] artoolkitmarker.type url url of the Image Descriptors, without extension artoolkitmarker.descriptorsUrl emitevents emits 'markerFound' and 'markerLost' events - ['true', 'false'] - smooth turn on/off camera smoothing - ['true', 'false'] - default: false - smoothCount number of matrices to smooth tracking over, more = smoother but slower follow - default: 5 - smoothTolerance distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still - default: 0.01 - smoothThreshold threshold for smoothing, will keep still unless enough matrices are over tolerance - default: 2 - size size of the marker in meter artoolkitmarker.size \u26a1\ufe0f It is suggested to use smooth , smoothCount and smoothTolerance because of weak stabilization of content in Image Tracking. Thanks to smoothing, content is way more stable, from 3D models to 2D videos.","title":"Image Tracking"},{"location":"image-tracking/#image-tracking","text":"Image Tracking makes possible to scan a picture, a drawing, any image, and show content over it. All the following examples are with A-Frame, for semplicity. You can use three.js if you want. See on the official repository the nft three.js example . All A-Frame examples for Image Tracking can be found here .","title":"Image Tracking"},{"location":"image-tracking/#getting-started-with-image-tracking","text":"Natural Feature Tracking or NFT is a technology that enables the use of images instead of markers like QR Codes or the Hiro marker. The software tracks interesting points in the image and using them, it estimates the position of the camera. These interesting points (aka \"Image Descriptors\") are created using the NFT Marker Creator , a tool available for creating NFT markers. It comes in two versions: the Web version (recommended), and the node.js version . There is also a fork of this project on the AR.js Github organisation, but as for now, Daniel Fernandes version works perfectly. Thanks to Daniel Fernandes for contribution on this docs section.","title":"Getting started with Image Tracking"},{"location":"image-tracking/#choose-good-images","text":"If you want to understand the creation of markers in more depth, check out the NFT Marker Creator wiki . It explains also why certain images work way better than others. An important factor is the DPI of the image: a good dpi (300 or more) will give a very good stabilization, while low DPI (like 72) will require the user to stay very still and close to the image, otherwise tracking will lag.","title":"Choose good images"},{"location":"image-tracking/#create-image-descriptors","text":"Once you have chosen your image, you can either use the NFT Marker Creator in its Web version or the node version. If you're using the node version, this is the basic command to run: node app.js -i path-to-the-img/image-name.jpg/png After that, you will find the Image Descriptors files on the output folder. In the web version, the generator will automatically download the files from your browser. In either cases, you will end up with three files as Image Descriptors, with .fset , .fset3 , .iset . Each of them will have the same prefix before the file extension. That one will be the Image Descriptor name that you will use on the AR.js web app. For example: with files trex.fset , trex.fset3 and trex.iset , your Image Descriptors name will be trex .","title":"Create Image Descriptors"},{"location":"image-tracking/#render-the-content","text":"Now it's time to create the actual AR web app. !-- import aframe and then ar.js with image tracking / location based features -- script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script !-- style for the loader -- style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -- div class= arjs-loader div Loading, please wait... /div /div !-- a-frame scene -- a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- a-nft is the anchor that defines an Image Tracking entity -- !-- on 'url' use the path to the Image Descriptors created before. -- !-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -- a-nft type= nft url= path-to-your-image-descriptors smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 !-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -- a-entity gltf-model= path-to-your-model scale= 5 5 5 position= 50 150 0 /a-entity /a-nft !-- static camera that moves according to the device movemenents -- a-entity camera /a-entity /a-scene /body See on the comments above, inline on the code, for explanations. You can refer to A-Frame docs to know everything about content and customization. You can add geometries, 3D models, videos, images. And you can customize their position, scale, rotation and so on. The only custom component here is the a-nft , the Image Tracking HTML anchor.","title":"Render the content"},{"location":"image-tracking/#lta-nftgt","text":"Here are the attributes for this entity Attribute Description Component Mapping type type of marker - ['nft' only valid value] artoolkitmarker.type url url of the Image Descriptors, without extension artoolkitmarker.descriptorsUrl emitevents emits 'markerFound' and 'markerLost' events - ['true', 'false'] - smooth turn on/off camera smoothing - ['true', 'false'] - default: false - smoothCount number of matrices to smooth tracking over, more = smoother but slower follow - default: 5 - smoothTolerance distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still - default: 0.01 - smoothThreshold threshold for smoothing, will keep still unless enough matrices are over tolerance - default: 2 - size size of the marker in meter artoolkitmarker.size \u26a1\ufe0f It is suggested to use smooth , smoothCount and smoothTolerance because of weak stabilization of content in Image Tracking. Thanks to smoothing, content is way more stable, from 3D models to 2D videos.","title":"&lt;a-nft\\&gt;"},{"location":"location-based/","text":"Location Based Location Based has been implemented only for A-Frame framework. This article gives you a first glance to Location Based on AR.js. It can be used for indoor (but with low precision) and outdoor geopositioning of AR content. You can load places statically, from HTML or from Javascript, or you can load your data from local/remote json, or even through API calls. Choice is yours. On the article above there are all the options explained, as tutorials. Following there's the API Reference. gps-camera Required : yes Max allowed per scene : 1 This component enables the Location AR. It has to be added to the camera entity. It makes possible to handle both position and rotation of the camera and it's used to determine where the user is pointing their device. For example: a-camera gps-camera rotation-reader /a-camera In addition to that, as you can see on the example above, we also have to add rotation-reader to handle rotation events. See here for more details. Properties Property Description Default Value alert Whether to show a message when GPS signal is under the positionMinAccuracy false positionMinAccuracy Minimum accuracy allowed for position signal 100 minDistance If set, places with a distance from the user lower than this value, are not showed. Only a positive value is allowed. Value is in meters. 0 (disabled) maxDistance If set, places with a distance from the user higher than this value, are not showed. Only a positive value is allowed. Value is in meters. 0 (disabled) simulateLatitude Setting this allows you to simulate the latitude of the camera, to aid in testing. 0 (disabled) simulateLongitude Setting this allows you to simulate the longitude of the camera, to aid in testing. 0 (disabled) simulateAltitude Setting this allows you to simulate the altitude of the camera in meters above sea level, to aid in testing. 0 (disabled) gps-entity-place Required : yes Max allowed per scene : no limit This component makes each entity GPS-trackable. This assigns a specific world position to an entity, so that the user can see it when their device is pointing to its position in the real world. If the user is far from the entity, it will seem smaller. If it's too far away, it won't be seen at all. It requires latitude and longitude as a single string parameter (example with a-box aframe primitive): a-box material= color: yellow gps-entity-place= latitude: your-latitude ; longitude: your-longitude / \u26a1\ufe0f In addition, you can use the a-frame \"position\" parameter to assign a y-value to change the height of the content. This value should be entered as meters above or below (if negative) the current camera height. For example, this would assign a height of 30 meters, and will be displayed relative to the gps-camera's current height: a-box material= color: yellow gps-entity-place= latitude: your-latitude ; longitude: your-longitude position= 0 30 0 / Properties No real property apart from the string that defined latitude and longitude together, as shown above. Custom Attributes The following are Custom Attributes that can be retrieved from gps-entity-place entities, for example: const distanceMsg = document.querySelector('[gps-entity-place]').getAttribute('distanceMsg'); console.log(distanceMsg); // 890 meters Custom Attribute Description Default Value distance Distance from user, updated at every user position update. Value in meters. 0 distanceMsg Distance from user as string, with unit, updated at every user position update. Value as distance meters/kilometers . '' Events Take a look at the UI and Events page for Location Based Custom Events. \u26a1\ufe0f Usually, in Location Based, it's nice to have the augmented content that will always face the user, so when you rotate the camera, 3D models or most of all, text, are well visible. Look at this example in order to create gps-entity-place entities that will always face the user (camera). Projected Camera Version The experimental 'projected camera' version of the location-based components for AR.js uses Spherical Mercator (aka EPSG:3857) to store both the camera position and the position of added points of interest and other geographical data. The rationale for this version is to allow easy addition of more complex geographic data such as roads and paths. Such data can be projected and added to an AR.js scene, and then, because Spherical Mercator units approximate to metres (away from the poles), the coordinates can be used directly as WebGL/A-Frame world coordinates. The two components for the projected camera version are gps-projected-camera and gps-projected-entity-place . Their interface is almost identical to gps-camera and gps-entity-place but they work differently internally. For example: a-camera gps-projected-camera rotation-reader /a-camera and: a-box color= yellow gps-projected-entity-place= latitude: your-latitude ; longitude: your-longitude / Note that internally, the latitude and longitude are converted to Spherical Mercator coordinates. As for gps-entity-place , you can specify an altitude using the y component of the position attribute: a-box color= yellow gps-projected-entity-place= latitude: your-latitude ; longitude: your-longitude position= 0 30 0 / Calculating world coordinates of arbitrary augmented content gps-projected-camera has some useful properties and methods which can be used to easily work with arbitrary augmented content (for example, polylines or polygons sourced from geodata APIs such as OpenStreetMap ). Before introducing these, it needs to be made clear that, in gps-projected-camera , the original GPS position is set as the world origin. So, if arbitrary content is to be added to the scene, and the source coordinates for this content is in unprojected (WGS84) latitude and longitude, it needs to be: projected to Spherical Mercator; and then converted to world coordinates relative to the original GPS position. On the other hand, only the second step is needed if the source coordinates are already projected. We'll look at each scenario now. Source data in WGS84 latitude/longitude The latLonToWorld(lat, lon) method of the gps-projected-camera component converts latitude and longitude directly to world coordinates, performing the projection as the first step and then calculating the world coordinates from the projected coordinates. It will return a 2-member array containing the x and z world coordinates, allowing the developer to calculate or specify the y coordinate (altitude) independently. Source data in Spherical Mercator An alternative scenario is when the augmented content has already been projected into Spherical Mercator and therefore does not need the initial projection step when added to an AR.js scene. This may occur when an API serves data in Spherical Mercator, for instance. In this case, we still need to convert the Spherical Mercator coordinates to world coordinates relative to the original GPS position. gps-projected-camera has an originCoordsProjected property, which represents the original GPS position in Spherical Mercator coordinates. This is a two-member array, containing the Spherical Mercator easting and northing, respectively, of the origin point. From this, we can therefore work out the world coordinates from Spherical Mercator coordinates: xWorld = featureEasting - originCoordsProjected[0] and zWorld = -(featureNorthing - originCoordsProjected[1]) where xWorld and zWorld are the world x and z coordinates of the augmented content, and featureEasting and featureNorthing are the content's Spherical Mercator coordinates. Note how we have to reverse the sign of z as increasing Spherical Mercator easting corresponds to increasing x in OpenGL coordinates, and increasing altitude corresponds to increasing y , but increasing Spherical Mercator northing corresponds to decreasing z .","title":"Location Based"},{"location":"location-based/#location-based","text":"Location Based has been implemented only for A-Frame framework. This article gives you a first glance to Location Based on AR.js. It can be used for indoor (but with low precision) and outdoor geopositioning of AR content. You can load places statically, from HTML or from Javascript, or you can load your data from local/remote json, or even through API calls. Choice is yours. On the article above there are all the options explained, as tutorials. Following there's the API Reference.","title":"Location Based"},{"location":"location-based/#gps-camera","text":"Required : yes Max allowed per scene : 1 This component enables the Location AR. It has to be added to the camera entity. It makes possible to handle both position and rotation of the camera and it's used to determine where the user is pointing their device. For example: a-camera gps-camera rotation-reader /a-camera In addition to that, as you can see on the example above, we also have to add rotation-reader to handle rotation events. See here for more details.","title":"gps-camera"},{"location":"location-based/#properties","text":"Property Description Default Value alert Whether to show a message when GPS signal is under the positionMinAccuracy false positionMinAccuracy Minimum accuracy allowed for position signal 100 minDistance If set, places with a distance from the user lower than this value, are not showed. Only a positive value is allowed. Value is in meters. 0 (disabled) maxDistance If set, places with a distance from the user higher than this value, are not showed. Only a positive value is allowed. Value is in meters. 0 (disabled) simulateLatitude Setting this allows you to simulate the latitude of the camera, to aid in testing. 0 (disabled) simulateLongitude Setting this allows you to simulate the longitude of the camera, to aid in testing. 0 (disabled) simulateAltitude Setting this allows you to simulate the altitude of the camera in meters above sea level, to aid in testing. 0 (disabled)","title":"Properties"},{"location":"location-based/#gps-entity-place","text":"Required : yes Max allowed per scene : no limit This component makes each entity GPS-trackable. This assigns a specific world position to an entity, so that the user can see it when their device is pointing to its position in the real world. If the user is far from the entity, it will seem smaller. If it's too far away, it won't be seen at all. It requires latitude and longitude as a single string parameter (example with a-box aframe primitive): a-box material= color: yellow gps-entity-place= latitude: your-latitude ; longitude: your-longitude / \u26a1\ufe0f In addition, you can use the a-frame \"position\" parameter to assign a y-value to change the height of the content. This value should be entered as meters above or below (if negative) the current camera height. For example, this would assign a height of 30 meters, and will be displayed relative to the gps-camera's current height: a-box material= color: yellow gps-entity-place= latitude: your-latitude ; longitude: your-longitude position= 0 30 0 /","title":"gps-entity-place"},{"location":"location-based/#properties_1","text":"No real property apart from the string that defined latitude and longitude together, as shown above.","title":"Properties"},{"location":"location-based/#custom-attributes","text":"The following are Custom Attributes that can be retrieved from gps-entity-place entities, for example: const distanceMsg = document.querySelector('[gps-entity-place]').getAttribute('distanceMsg'); console.log(distanceMsg); // 890 meters Custom Attribute Description Default Value distance Distance from user, updated at every user position update. Value in meters. 0 distanceMsg Distance from user as string, with unit, updated at every user position update. Value as distance meters/kilometers . ''","title":"Custom Attributes"},{"location":"location-based/#events","text":"Take a look at the UI and Events page for Location Based Custom Events. \u26a1\ufe0f Usually, in Location Based, it's nice to have the augmented content that will always face the user, so when you rotate the camera, 3D models or most of all, text, are well visible. Look at this example in order to create gps-entity-place entities that will always face the user (camera).","title":"Events"},{"location":"location-based/#projected-camera-version","text":"The experimental 'projected camera' version of the location-based components for AR.js uses Spherical Mercator (aka EPSG:3857) to store both the camera position and the position of added points of interest and other geographical data. The rationale for this version is to allow easy addition of more complex geographic data such as roads and paths. Such data can be projected and added to an AR.js scene, and then, because Spherical Mercator units approximate to metres (away from the poles), the coordinates can be used directly as WebGL/A-Frame world coordinates. The two components for the projected camera version are gps-projected-camera and gps-projected-entity-place . Their interface is almost identical to gps-camera and gps-entity-place but they work differently internally. For example: a-camera gps-projected-camera rotation-reader /a-camera and: a-box color= yellow gps-projected-entity-place= latitude: your-latitude ; longitude: your-longitude / Note that internally, the latitude and longitude are converted to Spherical Mercator coordinates. As for gps-entity-place , you can specify an altitude using the y component of the position attribute: a-box color= yellow gps-projected-entity-place= latitude: your-latitude ; longitude: your-longitude position= 0 30 0 /","title":"Projected Camera Version"},{"location":"location-based/#calculating-world-coordinates-of-arbitrary-augmented-content","text":"gps-projected-camera has some useful properties and methods which can be used to easily work with arbitrary augmented content (for example, polylines or polygons sourced from geodata APIs such as OpenStreetMap ). Before introducing these, it needs to be made clear that, in gps-projected-camera , the original GPS position is set as the world origin. So, if arbitrary content is to be added to the scene, and the source coordinates for this content is in unprojected (WGS84) latitude and longitude, it needs to be: projected to Spherical Mercator; and then converted to world coordinates relative to the original GPS position. On the other hand, only the second step is needed if the source coordinates are already projected. We'll look at each scenario now.","title":"Calculating world coordinates of arbitrary augmented content"},{"location":"location-based/#source-data-in-wgs84-latitudelongitude","text":"The latLonToWorld(lat, lon) method of the gps-projected-camera component converts latitude and longitude directly to world coordinates, performing the projection as the first step and then calculating the world coordinates from the projected coordinates. It will return a 2-member array containing the x and z world coordinates, allowing the developer to calculate or specify the y coordinate (altitude) independently.","title":"Source data in WGS84 latitude/longitude"},{"location":"location-based/#source-data-in-spherical-mercator","text":"An alternative scenario is when the augmented content has already been projected into Spherical Mercator and therefore does not need the initial projection step when added to an AR.js scene. This may occur when an API serves data in Spherical Mercator, for instance. In this case, we still need to convert the Spherical Mercator coordinates to world coordinates relative to the original GPS position. gps-projected-camera has an originCoordsProjected property, which represents the original GPS position in Spherical Mercator coordinates. This is a two-member array, containing the Spherical Mercator easting and northing, respectively, of the origin point. From this, we can therefore work out the world coordinates from Spherical Mercator coordinates: xWorld = featureEasting - originCoordsProjected[0] and zWorld = -(featureNorthing - originCoordsProjected[1]) where xWorld and zWorld are the world x and z coordinates of the augmented content, and featureEasting and featureNorthing are the content's Spherical Mercator coordinates. Note how we have to reverse the sign of z as increasing Spherical Mercator easting corresponds to increasing x in OpenGL coordinates, and increasing altitude corresponds to increasing y , but increasing Spherical Mercator northing corresponds to decreasing z .","title":"Source data in Spherical Mercator"},{"location":"marker-based/","text":"Marker Based Markers can be of three, different types: Hiro Barcode Pattern. To learn more about markers, please read this articles: AR.js basic Marker Based tutorial and Markers explanation Deliver AR.js experiences using only QRCodes (Markers inside QRCodes) . TL:DR Hiro Marker is the default one, not very useful actually Barcode markers are auto-generated markers, from matrix computations. Learn more on the above articles on how to use them. If you need the full list of barcode markers, here it is Pattern markers are custom ones, created starting from an image (very simple, hight contrast), loaded by the user. \u26a1\ufe0f You can create your Pattern Markers with this tool . It will generate an image to scan and a .patt file, to be loaded on the AR.js web app, in order for it to recognise the marker when running. How to choose good images for Pattern Markers Markers have a black border and high contrast shapes. Lately, we have added also white border markers with black background, altough the classic ones, with black border, behave better. Here's an article explaining all good practice on how to choose good images to be used to generate custom markers: 10 tips to enhance your AR.js app . API Reference for Marker Based A-Frame a-marker/ Here are the attributes for this entity Attribute Description Component Mapping type type of marker - ['pattern', 'barcode', 'unknown' ] artoolkitmarker.type size size of the marker in meter artoolkitmarker.size url url of the pattern - IIF type='pattern' artoolkitmarker.patternUrl value value of the barcode - IIF type='barcode' artoolkitmarker.barcodeValue preset parameters preset - ['hiro', 'kanji'] artoolkitmarker.preset emitevents emits 'markerFound' and 'markerLost' events - ['true', 'false'] - smooth turn on/off camera smoothing - ['true', 'false'] - default: false - smoothCount number of matrices to smooth tracking over, more = smoother but slower follow - default: 5 - smoothTolerance distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still - default: 0.01 - smoothThreshold threshold for smoothing, will keep still unless enough matrices are over tolerance - default: 2 - three.js threex-artoolkit threex.artoolkit is the three.js extension to easily handle artoolkit . Architecture threex.artoolkit is composed of 3 classes THREEx.ArToolkitSource : It is the image which is analyzed to do the position tracking. It can be the webcam, a video or even an image THREEx.ArToolkitContext : It is the main engine. It will actually find the marker position in the image source. THREEx.ArMarkerControls : it controls the position of the marker It use the classical three.js controls API . It will make sure to position your content right on top of the marker. THREEx.ArMarkerControls var parameters = { // size of the marker in meter size: 1, // type of marker - ['pattern', 'barcode', 'unknown' ] type: unknown , // url of the pattern - IIF type='pattern' patternUrl: null, // value of the barcode - IIF type='barcode' barcodeValue: null, // change matrix mode - [modelViewMatrix, cameraTransformMatrix] changeMatrixMode: modelViewMatrix , // turn on/off camera smoothing smooth: true, // number of matrices to smooth tracking over, more = smoother but slower follow smoothCount: 5, // distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still smoothTolerance: 0.01, // threshold for smoothing, will keep still unless enough matrices are over tolerance smoothThreshold: 2 }; THREEx.ArToolkitContext var parameters = { // debug - true if one should display artoolkit debug canvas, false otherwise debug: false, // the mode of detection - ['color', 'color_and_matrix', 'mono', 'mono_and_matrix'] detectionMode: 'color_and_matrix', // type of matrix code - valid iif detectionMode end with 'matrix' - [3x3, 3x3_HAMMING63, 3x3_PARITY65, 4x4, 4x4_BCH_13_9_3, 4x4_BCH_13_5_5] matrixCodeType: '3x3', // Pattern ratio for custom markers patternRatio: 0.5 // Labeling mode for markers - ['black_region', 'white_region'] // black_region: Black bordered markers on a white background, white_region: White bordered markers on a black background labelingMode: 'black_region', // url of the camera parameters cameraParametersUrl: THREEx.ArToolkitContext.baseURL + '../data/data/camera_para.dat', // tune the maximum rate of pose detection in the source image maxDetectionRate: 60, // resolution of at which we detect pose in the source image canvasWidth: 640, canvasHeight: 480, // enable image smoothing or not for canvas copy - default to true // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/imageSmoothingEnabled imageSmoothingEnabled : true, } THREEx.ArToolkitSource var parameters = { // type of source - ['webcam', 'image', 'video'] sourceType: webcam , // url of the source - valid if sourceType = image|video sourceUrl: null, // resolution of at which we initialize the source image sourceWidth: 640, sourceHeight: 480, // resolution displayed for the source displayWidth: 640, displayHeight: 480 };","title":"Marker Based"},{"location":"marker-based/#marker-based","text":"Markers can be of three, different types: Hiro Barcode Pattern. To learn more about markers, please read this articles: AR.js basic Marker Based tutorial and Markers explanation Deliver AR.js experiences using only QRCodes (Markers inside QRCodes) . TL:DR Hiro Marker is the default one, not very useful actually Barcode markers are auto-generated markers, from matrix computations. Learn more on the above articles on how to use them. If you need the full list of barcode markers, here it is Pattern markers are custom ones, created starting from an image (very simple, hight contrast), loaded by the user. \u26a1\ufe0f You can create your Pattern Markers with this tool . It will generate an image to scan and a .patt file, to be loaded on the AR.js web app, in order for it to recognise the marker when running.","title":"Marker Based"},{"location":"marker-based/#how-to-choose-good-images-for-pattern-markers","text":"Markers have a black border and high contrast shapes. Lately, we have added also white border markers with black background, altough the classic ones, with black border, behave better. Here's an article explaining all good practice on how to choose good images to be used to generate custom markers: 10 tips to enhance your AR.js app .","title":"How to choose good images for Pattern Markers"},{"location":"marker-based/#api-reference-for-marker-based","text":"","title":"API Reference for Marker Based"},{"location":"marker-based/#a-frame","text":"","title":"A-Frame"},{"location":"marker-based/#lta-markergt","text":"Here are the attributes for this entity Attribute Description Component Mapping type type of marker - ['pattern', 'barcode', 'unknown' ] artoolkitmarker.type size size of the marker in meter artoolkitmarker.size url url of the pattern - IIF type='pattern' artoolkitmarker.patternUrl value value of the barcode - IIF type='barcode' artoolkitmarker.barcodeValue preset parameters preset - ['hiro', 'kanji'] artoolkitmarker.preset emitevents emits 'markerFound' and 'markerLost' events - ['true', 'false'] - smooth turn on/off camera smoothing - ['true', 'false'] - default: false - smoothCount number of matrices to smooth tracking over, more = smoother but slower follow - default: 5 - smoothTolerance distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still - default: 0.01 - smoothThreshold threshold for smoothing, will keep still unless enough matrices are over tolerance - default: 2 -","title":"&lt;a-marker/&gt;"},{"location":"marker-based/#threejs","text":"","title":"three.js"},{"location":"marker-based/#threex-artoolkit","text":"threex.artoolkit is the three.js extension to easily handle artoolkit .","title":"threex-artoolkit"},{"location":"marker-based/#architecture","text":"threex.artoolkit is composed of 3 classes THREEx.ArToolkitSource : It is the image which is analyzed to do the position tracking. It can be the webcam, a video or even an image THREEx.ArToolkitContext : It is the main engine. It will actually find the marker position in the image source. THREEx.ArMarkerControls : it controls the position of the marker It use the classical three.js controls API . It will make sure to position your content right on top of the marker.","title":"Architecture"},{"location":"marker-based/#threexarmarkercontrols","text":"var parameters = { // size of the marker in meter size: 1, // type of marker - ['pattern', 'barcode', 'unknown' ] type: unknown , // url of the pattern - IIF type='pattern' patternUrl: null, // value of the barcode - IIF type='barcode' barcodeValue: null, // change matrix mode - [modelViewMatrix, cameraTransformMatrix] changeMatrixMode: modelViewMatrix , // turn on/off camera smoothing smooth: true, // number of matrices to smooth tracking over, more = smoother but slower follow smoothCount: 5, // distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still smoothTolerance: 0.01, // threshold for smoothing, will keep still unless enough matrices are over tolerance smoothThreshold: 2 };","title":"THREEx.ArMarkerControls"},{"location":"marker-based/#threexartoolkitcontext","text":"var parameters = { // debug - true if one should display artoolkit debug canvas, false otherwise debug: false, // the mode of detection - ['color', 'color_and_matrix', 'mono', 'mono_and_matrix'] detectionMode: 'color_and_matrix', // type of matrix code - valid iif detectionMode end with 'matrix' - [3x3, 3x3_HAMMING63, 3x3_PARITY65, 4x4, 4x4_BCH_13_9_3, 4x4_BCH_13_5_5] matrixCodeType: '3x3', // Pattern ratio for custom markers patternRatio: 0.5 // Labeling mode for markers - ['black_region', 'white_region'] // black_region: Black bordered markers on a white background, white_region: White bordered markers on a black background labelingMode: 'black_region', // url of the camera parameters cameraParametersUrl: THREEx.ArToolkitContext.baseURL + '../data/data/camera_para.dat', // tune the maximum rate of pose detection in the source image maxDetectionRate: 60, // resolution of at which we detect pose in the source image canvasWidth: 640, canvasHeight: 480, // enable image smoothing or not for canvas copy - default to true // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/imageSmoothingEnabled imageSmoothingEnabled : true, }","title":"THREEx.ArToolkitContext"},{"location":"marker-based/#threexartoolkitsource","text":"var parameters = { // type of source - ['webcam', 'image', 'video'] sourceType: webcam , // url of the source - valid if sourceType = image|video sourceUrl: null, // resolution of at which we initialize the source image sourceWidth: 640, sourceHeight: 480, // resolution displayed for the source displayWidth: 640, displayHeight: 480 };","title":"THREEx.ArToolkitSource"},{"location":"ui-events/","text":"UI and Custom Events To make AR.js based Web App looking better and add UI capabilities, it's possible to treat is as common website. Here you will learn how to use Raycaster, Custom Events and Interaction with overlayed DOM elements. Handle clicks on AR content It's now possible to use AR.js (marker based or image tracking) with a-frame latest versions (1.0.0 and above) in order to have touch gestures to zoom and rotate your content! Disclaimer: this will work for your entire a-scene , so it's not a real option if you have to handle different interactions for multiple markers. It will work like charm if you have one marker/image for scene. Check Fabio Cort\u00e8s great walkthrough in order to add this feature on your AR.js web app. You can use this exact approach for Image Tracking a-nft and Marker Based a-entity elements. The clickhandler name can be customized, you can choose the one you like most, it's just a reference. Keep in mind that this click/touch interaction is not handled by AR.js at all, it is all A-Frame based. Always look on the A-Frame documentation for more details. Check out the tutorial Interaction with Overlayed DOM content You can add interations by adding DOM HTML elements on the body . For example, starting from this example: !DOCTYPE html html script src= https://aframe.io/releases/1.0.4/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html We can add on the body, outside the a-scene : div class= buttons button class= say-hi-button /button /div Then, we need to add some CSS to absolute positioning the DIV and BUTTON, and also some scripting to listen to click events. You can customize your a-scene or content, like 3D models, play video, and so on. See on A-Frame Docs on how to change entity properties and work with events: https://aframe.io/docs/1.0.0/introduction/javascript-events-dom-apis.html. We will end up with the following code: !DOCTYPE html html script src= https://aframe.io/releases/1.0.4/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script script window.onload = function () { document .querySelector( .say-hi-button ) .addEventListener( click , function () { // here you can change also a-scene or a-entity properties, like // changing your 3D model source, size, position and so on // or you can just open links, trigger actions... alert( Hi there! ); }); }; /script style .buttons { position: absolute; bottom: 0; left: 0; width: 100%; height: 5em; display: flex; justify-content: center; align-items: center; z-index: 10; } .say-hi-button { padding: 0.25em; border-radius: 4px; border: none; background: white; color: black; width: 4em; height: 2em; } /style body style= margin : 0px; overflow: hidden; div class= buttons button class= say-hi-button SAY HI! /button /div a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html Custom Events AR.js dispatches several Custom Events. Some of them are general, others are specific for AR Feature. Here's the full list. Custom Event name Description Payload Source File Feature arjs-video-loaded Fired when camera video stream has been appended to the DOM { detail: { component: HTMLElement }} threex-artoolkitsource.js all camera-error Fired when camera video stream could not be retrieved { error: Error } threex-artoolkitsource.js all camera-init Fired when camera video stream has been retrieved correctly { stream: MediaStream } threex-artoolkitsource.js all markerFound Fired when a marker in Marker Based, or a picture in Image Tracking, has been found - component-anchor.js only Image Tracking and Marker Based markerLost Fired when a marker in Marker Based, or a picture in Image Tracking, has been lost - component-anchor.js only Image Tracking and Marker Based arjs-nft-loaded Fired when a nft marker is full loaded threex-armarkercontrols-nft-start.js only Image Tracking gps-camera-update-positon Fired when gps-camera has updated its position { detail: { position: GeolocationCoordinates , origin: GeolocationCoordinates }} gps-camera.js only Location Based gps-entity-place-update-positon Fired when gps-entity-place has updated its position { detail: { distance: Number }} gps-entity-place.js only Location Based gps-entity-place-added Fired when the gps-entity-place has been added { detail: { component: HTMLElement }} gps-entity-place.js only Location Based gps-camera-origin-coord-set Fired when the origin coordinates are set - gps-camera.js only Location Based gps-entity-place-loaded Fired when the gps-entity-place has been - see 'loaded' event of A-Frame entities { detail: { component: HTMLElement }} gps-entity-place.js only Location Based Internal Loading Events \u26a1\ufe0f Both Image Tracking and Location Based automatically handle an internal event when origin location has been set Image Tracking (Image Descriptors) are fully loaded And automatically remove from the DOM elements that match the .arjs-loader selector. You can add any custom loader that will be remove in the above situations, just use the .arjs-loader class on it. Trigger actions when image has been found You can trigger any action you want when marker/image has been found. You can avoid linking a content to a marker/image and only trigger an action (like a redirect to an external website) when the anchor has been found by the camera. script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style script AFRAME.registerComponent('markerhandler', { init: function () { this.el.sceneEl.addEventListener('markerFound', () = { // redirect to custom URL window.location = 'https://github.com/AR-js-org/AR.js'; }); }); }, /script body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded -- div class= arjs-loader div Loading, please wait... /div /div a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors proxy to avoid cross-origin problems -- !-- we use the trex image shown on the homepage of the docs -- a-nft markerhandler type= nft url= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex /a-nft a-entity camera /a-entity /a-scene /body Trigger action when marker has been found script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script script AFRAME.registerComponent('markerhandler', { init: function () { this.el.sceneEl.addEventListener('markerFound', () = { // redirect to custom URL e.g. google.com window.location = 'https://www.google.com/'; }) } }); /script body style= margin : 0px; overflow: hidden; a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam; debugUIEnabled: false; detectionMode: mono_and_matrix; matrixCodeType: 3x3; a-marker markerhandler type='barcode' value='7' a-box position='0 0.5 0' color= yellow /a-box /a-marker a-entity camera /a-entity /a-scene /body","title":"UI and Events"},{"location":"ui-events/#ui-and-custom-events","text":"To make AR.js based Web App looking better and add UI capabilities, it's possible to treat is as common website. Here you will learn how to use Raycaster, Custom Events and Interaction with overlayed DOM elements.","title":"UI and Custom Events"},{"location":"ui-events/#handle-clicks-on-ar-content","text":"It's now possible to use AR.js (marker based or image tracking) with a-frame latest versions (1.0.0 and above) in order to have touch gestures to zoom and rotate your content! Disclaimer: this will work for your entire a-scene , so it's not a real option if you have to handle different interactions for multiple markers. It will work like charm if you have one marker/image for scene. Check Fabio Cort\u00e8s great walkthrough in order to add this feature on your AR.js web app. You can use this exact approach for Image Tracking a-nft and Marker Based a-entity elements. The clickhandler name can be customized, you can choose the one you like most, it's just a reference. Keep in mind that this click/touch interaction is not handled by AR.js at all, it is all A-Frame based. Always look on the A-Frame documentation for more details. Check out the tutorial","title":"Handle clicks on AR content"},{"location":"ui-events/#interaction-with-overlayed-dom-content","text":"You can add interations by adding DOM HTML elements on the body . For example, starting from this example: !DOCTYPE html html script src= https://aframe.io/releases/1.0.4/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html We can add on the body, outside the a-scene : div class= buttons button class= say-hi-button /button /div Then, we need to add some CSS to absolute positioning the DIV and BUTTON, and also some scripting to listen to click events. You can customize your a-scene or content, like 3D models, play video, and so on. See on A-Frame Docs on how to change entity properties and work with events: https://aframe.io/docs/1.0.0/introduction/javascript-events-dom-apis.html. We will end up with the following code: !DOCTYPE html html script src= https://aframe.io/releases/1.0.4/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script script window.onload = function () { document .querySelector( .say-hi-button ) .addEventListener( click , function () { // here you can change also a-scene or a-entity properties, like // changing your 3D model source, size, position and so on // or you can just open links, trigger actions... alert( Hi there! ); }); }; /script style .buttons { position: absolute; bottom: 0; left: 0; width: 100%; height: 5em; display: flex; justify-content: center; align-items: center; z-index: 10; } .say-hi-button { padding: 0.25em; border-radius: 4px; border: none; background: white; color: black; width: 4em; height: 2em; } /style body style= margin : 0px; overflow: hidden; div class= buttons button class= say-hi-button SAY HI! /button /div a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html","title":"Interaction with Overlayed DOM content"},{"location":"ui-events/#custom-events","text":"AR.js dispatches several Custom Events. Some of them are general, others are specific for AR Feature. Here's the full list. Custom Event name Description Payload Source File Feature arjs-video-loaded Fired when camera video stream has been appended to the DOM { detail: { component: HTMLElement }} threex-artoolkitsource.js all camera-error Fired when camera video stream could not be retrieved { error: Error } threex-artoolkitsource.js all camera-init Fired when camera video stream has been retrieved correctly { stream: MediaStream } threex-artoolkitsource.js all markerFound Fired when a marker in Marker Based, or a picture in Image Tracking, has been found - component-anchor.js only Image Tracking and Marker Based markerLost Fired when a marker in Marker Based, or a picture in Image Tracking, has been lost - component-anchor.js only Image Tracking and Marker Based arjs-nft-loaded Fired when a nft marker is full loaded threex-armarkercontrols-nft-start.js only Image Tracking gps-camera-update-positon Fired when gps-camera has updated its position { detail: { position: GeolocationCoordinates , origin: GeolocationCoordinates }} gps-camera.js only Location Based gps-entity-place-update-positon Fired when gps-entity-place has updated its position { detail: { distance: Number }} gps-entity-place.js only Location Based gps-entity-place-added Fired when the gps-entity-place has been added { detail: { component: HTMLElement }} gps-entity-place.js only Location Based gps-camera-origin-coord-set Fired when the origin coordinates are set - gps-camera.js only Location Based gps-entity-place-loaded Fired when the gps-entity-place has been - see 'loaded' event of A-Frame entities { detail: { component: HTMLElement }} gps-entity-place.js only Location Based","title":"Custom Events"},{"location":"ui-events/#internal-loading-events","text":"\u26a1\ufe0f Both Image Tracking and Location Based automatically handle an internal event when origin location has been set Image Tracking (Image Descriptors) are fully loaded And automatically remove from the DOM elements that match the .arjs-loader selector. You can add any custom loader that will be remove in the above situations, just use the .arjs-loader class on it.","title":"Internal Loading Events"},{"location":"ui-events/#trigger-actions-when-image-has-been-found","text":"You can trigger any action you want when marker/image has been found. You can avoid linking a content to a marker/image and only trigger an action (like a redirect to an external website) when the anchor has been found by the camera. script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style script AFRAME.registerComponent('markerhandler', { init: function () { this.el.sceneEl.addEventListener('markerFound', () = { // redirect to custom URL window.location = 'https://github.com/AR-js-org/AR.js'; }); }); }, /script body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded -- div class= arjs-loader div Loading, please wait... /div /div a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors proxy to avoid cross-origin problems -- !-- we use the trex image shown on the homepage of the docs -- a-nft markerhandler type= nft url= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex /a-nft a-entity camera /a-entity /a-scene /body","title":"Trigger actions when image has been found"},{"location":"ui-events/#trigger-action-when-marker-has-been-found","text":"script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script script AFRAME.registerComponent('markerhandler', { init: function () { this.el.sceneEl.addEventListener('markerFound', () = { // redirect to custom URL e.g. google.com window.location = 'https://www.google.com/'; }) } }); /script body style= margin : 0px; overflow: hidden; a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam; debugUIEnabled: false; detectionMode: mono_and_matrix; matrixCodeType: 3x3; a-marker markerhandler type='barcode' value='7' a-box position='0 0.5 0' color= yellow /a-box /a-marker a-entity camera /a-entity /a-scene /body","title":"Trigger action when marker has been found"}]}