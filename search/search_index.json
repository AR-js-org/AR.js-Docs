{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AR.js - Augmented Reality on the Web AR.js is a lightweight library for Augmented Reality on the Web, coming with features like Image Tracking, Location based AR and Marker tracking. Why AR.js We believe in the Web, a collaborative and accessible place. We also believe in the Augmented Reality technology, as a new communication medium, that can help people to see the reality in new, exciting ways. We see Augmented Reality (AR) used everyday for a lot of useful applications, from art, to education, also for fun. We strongly believe that such a powerful technology, that can help people and leverage their creativity, should be free in some way. Also collaborative, if possible. And so, we continue the work started by Jerome Etienne, in bringing AR on the Web, as a free and Open Source technology. Thank you for being interested in this, if you'd like to collaborate in any way, contact us ( https://twitter.com/nicolocarp ). The project is now under a Github organization, that you can find at https://github.com/ar-js-org and you can ask to be part of it, for free. AR types Ar.js features the following types of Augmented Reality, on the Web: Image Tracking Location Based AR Marker Tracking. Key points Very Fast : It runs efficiently even on phones Web-based : It is a pure web solution, so no installation required. Full javascript based on three.js + A-Frame + jsartoolkit5 Open Source : It is completely open source and free of charge! Standards : It works on any phone with webgl and webrtc AR.js has reached version 3. This is the official repository: https://github.com/AR-js-org/AR.js . If you want to visit the old AR.js repository, here it is: https://github.com/jeromeetienne/AR.js . Import the library AR.js from version 3 has a new structure. AR.js is coming in two, different build. They are both maintained. They are exclusive. The file you want to import depends on what features you want, and also which render library you want to use (A-Frame or three.js). AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . You can import AR.js in one version of your choice, using the script tag on your HTML. AR.js with Image Tracking + Location Based AR Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar-nft.js AR.js with Marker Tracking + Location Based AR: Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar.js Requirements Some requirements and known restrictions are listed below: It works on every phone with webgl and webrtc . Marker based is very lightweight, while Image Tracking is more CPU consuming. You cannot use Chrome on iOS, as Chrome on iOS did not support, at the moment, camera access On device with multi-cameras, Chrome may have problems on detecting the right one. Please use Firefox if you find that AR.js opens on the wrong camera. There is an open issue for this. Image Tracking, as for now, works only on mobile devices (due to aspect ratio issues) To work with Location Based feature, your phone needs to have GPS sensors. Please, read carefully all suggestions that AR.js pops up for Location Based on iOS, as iOS requires user actions to activate geoposition. Location Based feature is only available on A-Frame Location Based can work with A-Frame up to version 0.9.2. Compatibility with A-Frame v1.0.0 is work in progress. Always deploy under https Accessing to the phone camera or to camera GPS sensors, due to major browsers restrictions, can be done only under https websites. All the examples you will see, and all AR.js web apps in general, have to be run on a server. You can use local server or deploy the static web app on the web. Please, always run your examples on secure connections servers or localhost. Github Pages is a great way to have free and live websites under https. Getting started Here we present three, basic examples, one for each AR feature. For specific documentation, on the top menu you can find every section, or you can click on the following links: Image Tracking Documentation Location Based Documentation Marker Based Documentation Image Tracking Example Please follow this simple steps: Create a new project with the code below (or try this codepen and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded -- div class= arjs-loader div Loading, please wait... /div /div a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors-anywhere proxy to avoid cross-origin problems -- a-nft type= nft url= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 a-entity gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf scale= 5 5 5 position= 50 150 0 /a-entity /a-nft a-entity camera /a-entity /a-scene /body Location Based Example Please follow this simple steps: Create a new project with the following snippet, and change add-your-latitude and add-your-longitude with your latitude and longitude, without the . Run it on a server Activate GPS on your phone and navigate to the example URL Look around. You should see the text looking at you, appearing in the requested position, even if you look around and move. !DOCTYPE html html head meta charset= utf-8 / meta http-equiv= X-UA-Compatible content= IE=edge / title GeoAR.js demo /title !-- with location based, use aframe v0.9.2 -- script src= https://aframe.io/releases/0.9.2/aframe.min.js /script script src= https://unpkg.com/aframe-look-at-component@0.8.0/dist/aframe-look-at-component.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script /head body style= margin: 0; overflow: hidden; a-scene vr-mode-ui= enabled: false embedded arjs= sourceType: webcam; debugUIEnabled: false; a-text value= This content will always face you. look-at= [gps-camera] scale= 120 120 120 gps-entity-place= latitude: add-your-latitude ; longitude: add-your-longitude ; /a-text a-camera gps-camera rotation-reader /a-camera /a-scene /body /html Marker Based Example Please follow this simple steps: Create a new project with the code below (or try this codepen and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. !DOCTYPE html html script src= https://aframe.io/releases/1.0.0/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html Advanced stuff AR.js offers two ways, with A-Frame, to interact with the web page: clicks/touches events and Overlayed DOM interaction. Also, there are several Custom Events triggered during the life cycle of an AR.js web app. You can learn more about these aspects on the UI and Events section . AR.js architecture AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . three.js folder contains source code for AR.js core, Marker based and Image Tracking examples for AR.js three.js based build for three.js AR.js based vendor stuff (jsartoolkit5) workers (used for Image Tracking). When you find files that ends with -nft suffix, they're boundled only with the Image Tracking version. A-Frame version of AR.js uses three.js parts as its core. A-Frame here is it simply a wrapper to write AR with Custom Components in HTML. aframe folder contains source code for AR.js A-Frame (aka wrappers for Marker Based, Image Tracking components) source code for Location Based build for A-Frame AR.js based examples for A-Frame AR.js.","title":"Home"},{"location":"#arjs-augmented-reality-on-the-web","text":"AR.js is a lightweight library for Augmented Reality on the Web, coming with features like Image Tracking, Location based AR and Marker tracking.","title":"AR.js - Augmented Reality on the Web"},{"location":"#why-arjs","text":"We believe in the Web, a collaborative and accessible place. We also believe in the Augmented Reality technology, as a new communication medium, that can help people to see the reality in new, exciting ways. We see Augmented Reality (AR) used everyday for a lot of useful applications, from art, to education, also for fun. We strongly believe that such a powerful technology, that can help people and leverage their creativity, should be free in some way. Also collaborative, if possible. And so, we continue the work started by Jerome Etienne, in bringing AR on the Web, as a free and Open Source technology. Thank you for being interested in this, if you'd like to collaborate in any way, contact us ( https://twitter.com/nicolocarp ). The project is now under a Github organization, that you can find at https://github.com/ar-js-org and you can ask to be part of it, for free.","title":"Why AR.js"},{"location":"#ar-types","text":"Ar.js features the following types of Augmented Reality, on the Web: Image Tracking Location Based AR Marker Tracking.","title":"AR types"},{"location":"#key-points","text":"Very Fast : It runs efficiently even on phones Web-based : It is a pure web solution, so no installation required. Full javascript based on three.js + A-Frame + jsartoolkit5 Open Source : It is completely open source and free of charge! Standards : It works on any phone with webgl and webrtc AR.js has reached version 3. This is the official repository: https://github.com/AR-js-org/AR.js . If you want to visit the old AR.js repository, here it is: https://github.com/jeromeetienne/AR.js .","title":"Key points"},{"location":"#import-the-library","text":"AR.js from version 3 has a new structure. AR.js is coming in two, different build. They are both maintained. They are exclusive. The file you want to import depends on what features you want, and also which render library you want to use (A-Frame or three.js). AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . You can import AR.js in one version of your choice, using the script tag on your HTML. AR.js with Image Tracking + Location Based AR Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar-nft.js AR.js with Marker Tracking + Location Based AR: Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar.js","title":"Import the library"},{"location":"#requirements","text":"Some requirements and known restrictions are listed below: It works on every phone with webgl and webrtc . Marker based is very lightweight, while Image Tracking is more CPU consuming. You cannot use Chrome on iOS, as Chrome on iOS did not support, at the moment, camera access On device with multi-cameras, Chrome may have problems on detecting the right one. Please use Firefox if you find that AR.js opens on the wrong camera. There is an open issue for this. Image Tracking, as for now, works only on mobile devices (due to aspect ratio issues) To work with Location Based feature, your phone needs to have GPS sensors. Please, read carefully all suggestions that AR.js pops up for Location Based on iOS, as iOS requires user actions to activate geoposition. Location Based feature is only available on A-Frame Location Based can work with A-Frame up to version 0.9.2. Compatibility with A-Frame v1.0.0 is work in progress.","title":"Requirements"},{"location":"#always-deploy-under-https","text":"Accessing to the phone camera or to camera GPS sensors, due to major browsers restrictions, can be done only under https websites. All the examples you will see, and all AR.js web apps in general, have to be run on a server. You can use local server or deploy the static web app on the web. Please, always run your examples on secure connections servers or localhost. Github Pages is a great way to have free and live websites under https.","title":"Always deploy under https"},{"location":"#getting-started","text":"Here we present three, basic examples, one for each AR feature. For specific documentation, on the top menu you can find every section, or you can click on the following links: Image Tracking Documentation Location Based Documentation Marker Based Documentation","title":"Getting started"},{"location":"#image-tracking-example","text":"Please follow this simple steps: Create a new project with the code below (or try this codepen and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded -- div class= arjs-loader div Loading, please wait... /div /div a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors-anywhere proxy to avoid cross-origin problems -- a-nft type= nft url= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 a-entity gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf scale= 5 5 5 position= 50 150 0 /a-entity /a-nft a-entity camera /a-entity /a-scene /body","title":"Image Tracking Example"},{"location":"#location-based-example","text":"Please follow this simple steps: Create a new project with the following snippet, and change add-your-latitude and add-your-longitude with your latitude and longitude, without the . Run it on a server Activate GPS on your phone and navigate to the example URL Look around. You should see the text looking at you, appearing in the requested position, even if you look around and move. !DOCTYPE html html head meta charset= utf-8 / meta http-equiv= X-UA-Compatible content= IE=edge / title GeoAR.js demo /title !-- with location based, use aframe v0.9.2 -- script src= https://aframe.io/releases/0.9.2/aframe.min.js /script script src= https://unpkg.com/aframe-look-at-component@0.8.0/dist/aframe-look-at-component.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script /head body style= margin: 0; overflow: hidden; a-scene vr-mode-ui= enabled: false embedded arjs= sourceType: webcam; debugUIEnabled: false; a-text value= This content will always face you. look-at= [gps-camera] scale= 120 120 120 gps-entity-place= latitude: add-your-latitude ; longitude: add-your-longitude ; /a-text a-camera gps-camera rotation-reader /a-camera /a-scene /body /html","title":"Location Based Example"},{"location":"#marker-based-example","text":"Please follow this simple steps: Create a new project with the code below (or try this codepen and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. !DOCTYPE html html script src= https://aframe.io/releases/1.0.0/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html","title":"Marker Based Example"},{"location":"#advanced-stuff","text":"AR.js offers two ways, with A-Frame, to interact with the web page: clicks/touches events and Overlayed DOM interaction. Also, there are several Custom Events triggered during the life cycle of an AR.js web app. You can learn more about these aspects on the UI and Events section .","title":"Advanced stuff"},{"location":"#arjs-architecture","text":"AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . three.js folder contains source code for AR.js core, Marker based and Image Tracking examples for AR.js three.js based build for three.js AR.js based vendor stuff (jsartoolkit5) workers (used for Image Tracking). When you find files that ends with -nft suffix, they're boundled only with the Image Tracking version. A-Frame version of AR.js uses three.js parts as its core. A-Frame here is it simply a wrapper to write AR with Custom Components in HTML. aframe folder contains source code for AR.js A-Frame (aka wrappers for Marker Based, Image Tracking components) source code for Location Based build for A-Frame AR.js based examples for A-Frame AR.js.","title":"AR.js architecture"},{"location":"about/","text":"This project has been created by @jeromeetienne and it is now maintained by @nicolocarpignoli . For frequent updates on AR.js you can follow @nicolocarp and Watch this repo! After months of work, we have changed AR.js for good. The aim was to make it a true, free alternative to paid Web AR solutions. We don't know if we're already there, but now the path is clear, at least. We have worked hard, spent many days and nights\u200a-\u200aobviously, we are coders, what did you expect?\u200a-\u200aand we are now so thrilled to share this achievement with the community. We know that it can be better, we know its limitations, but we would love to share this journey's result. AR.js is now under a Github organisation, that means, more collaborative than ever. It has a new structure, and a lot of new code. And most of all, we've added Image Tracking, what we felt was the missing piece for a true alternative to Web AR. A huge, huge thanks to the wonderful guys who made this possible: Walter Perdan Thorsten Bux Daniel Fernandes misdake hatsumatsu and many more. It was great to built this with all of you.","title":"About"},{"location":"image-tracking/","text":"Image Tracking Image Tracking makes possible to scan a picture, drawing, any image, and show content over it. All the following examples are with A-Frame, for semplicity. You can use three.js if you want. See on the official repository the three.js examples , search for 'nft' example. All A-Frame examples for Image Tracking can be found here . Getting started with Image Tracking Thanks to Daniel Fernandes for contribution on this docs section. Natural Feature Tracking or NFT is a technology that enables the use of images instead of markers like QR Codes or the Hiro marker. The software tracks interesting points in the image and from that it estimates the position of the camera. These interesting points (aka \"Image Descriptors\") are created using the NFT Marker Creator , a tool available to you for creating NFT markers, it has two versions: the Web version (recommended), and the node.js version . There is also a fork of this project on the AR.js Github organisation, but as for now, Daniel Fernandes version works perfectly. Choose good images If you want to understand the creation of markers in more depth, check out the NFT Marker Creator wiki . Create Image Descriptors Once you have chosen your image, you can either use the web version or the node version. If you're using the node version, this is the basic command to run: node app.js -i path-to-the-img/image-name.jpg/png And you will find the Image Descriptors files on the output folder. In the web version, the generator will automatically download the files from your browser. In either cases, you will end up with three files as Image Descriptors, with .fset , .fset3 , .iset . Each of them will have the same prefix before the file extension. That one will be the Image Descriptor name that you will use on the AR.js web app. Render the content Now it's time to create the actual Web app. !-- import aframe and then ar.js with image tracking / location based features -- script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script !-- style for the loader -- style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded. this may take a while according to the device computational power -- div class= arjs-loader div Loading, please wait... /div /div !-- a-frame scene -- a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors-anywhere proxy to avoid cross-origin problems -- !-- a-nft is the anchor that defines an Image Tracking entity -- !-- on 'url' use the path to the Image Descriptors created before. -- !-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -- a-nft type= nft url= path-to-your-image-descriptors smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 !-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -- a-entity gltf-model= path-to-your-model scale= 5 5 5 position= 50 150 0 /a-entity /a-nft !-- static camera that moves according to the device movemenents. it always points towards center of the screen -- a-entity camera /a-entity /a-scene /body See on the comments above, inline on the code, for explanations. You can refer to A-Frame docs to know everything about content and customization. You can add geometries, 3D models, videos, images. And you can customize their position, scale, rotation and so on. The only custom component here is the a-nft , the Image Tracking HTML anchor. a-nft\\ Here are the attributes for this entity Attribute Description Component Mapping type type of marker - ['nft' only valid value] artoolkitmarker.type url url of the Image Descriptors, without extension artoolkitmarker.descriptorsUrl emitevents emits 'markerFound' and 'markerLost' events - ['true', 'false'] - smooth turn on/off camera smoothing - ['true', 'false'] - default: false - smoothCount number of matrices to smooth tracking over, more = smoother but slower follow - default: 5 - smoothTolerance distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still - default: 0.01 - smoothThreshold threshold for smoothing, will keep still unless enough matrices are over tolerance - default: 2 - size size of the marker in meter artoolkitmarker.size \u26a1\ufe0f It is suggested to use smooth , smoothCount and smoothTolerance because of weak stabilization of content in Image Tracking. Thanks to smoothing, content is way more stable, from 3D models to 2D videos.","title":"Image Tracking"},{"location":"image-tracking/#image-tracking","text":"Image Tracking makes possible to scan a picture, drawing, any image, and show content over it. All the following examples are with A-Frame, for semplicity. You can use three.js if you want. See on the official repository the three.js examples , search for 'nft' example. All A-Frame examples for Image Tracking can be found here .","title":"Image Tracking"},{"location":"image-tracking/#getting-started-with-image-tracking","text":"Thanks to Daniel Fernandes for contribution on this docs section. Natural Feature Tracking or NFT is a technology that enables the use of images instead of markers like QR Codes or the Hiro marker. The software tracks interesting points in the image and from that it estimates the position of the camera. These interesting points (aka \"Image Descriptors\") are created using the NFT Marker Creator , a tool available to you for creating NFT markers, it has two versions: the Web version (recommended), and the node.js version . There is also a fork of this project on the AR.js Github organisation, but as for now, Daniel Fernandes version works perfectly.","title":"Getting started with Image Tracking"},{"location":"image-tracking/#choose-good-images","text":"If you want to understand the creation of markers in more depth, check out the NFT Marker Creator wiki .","title":"Choose good images"},{"location":"image-tracking/#create-image-descriptors","text":"Once you have chosen your image, you can either use the web version or the node version. If you're using the node version, this is the basic command to run: node app.js -i path-to-the-img/image-name.jpg/png And you will find the Image Descriptors files on the output folder. In the web version, the generator will automatically download the files from your browser. In either cases, you will end up with three files as Image Descriptors, with .fset , .fset3 , .iset . Each of them will have the same prefix before the file extension. That one will be the Image Descriptor name that you will use on the AR.js web app.","title":"Create Image Descriptors"},{"location":"image-tracking/#render-the-content","text":"Now it's time to create the actual Web app. !-- import aframe and then ar.js with image tracking / location based features -- script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script !-- style for the loader -- style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded. this may take a while according to the device computational power -- div class= arjs-loader div Loading, please wait... /div /div !-- a-frame scene -- a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors-anywhere proxy to avoid cross-origin problems -- !-- a-nft is the anchor that defines an Image Tracking entity -- !-- on 'url' use the path to the Image Descriptors created before. -- !-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -- a-nft type= nft url= path-to-your-image-descriptors smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 !-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -- a-entity gltf-model= path-to-your-model scale= 5 5 5 position= 50 150 0 /a-entity /a-nft !-- static camera that moves according to the device movemenents. it always points towards center of the screen -- a-entity camera /a-entity /a-scene /body See on the comments above, inline on the code, for explanations. You can refer to A-Frame docs to know everything about content and customization. You can add geometries, 3D models, videos, images. And you can customize their position, scale, rotation and so on. The only custom component here is the a-nft , the Image Tracking HTML anchor.","title":"Render the content"},{"location":"image-tracking/#lta-nftgt","text":"Here are the attributes for this entity Attribute Description Component Mapping type type of marker - ['nft' only valid value] artoolkitmarker.type url url of the Image Descriptors, without extension artoolkitmarker.descriptorsUrl emitevents emits 'markerFound' and 'markerLost' events - ['true', 'false'] - smooth turn on/off camera smoothing - ['true', 'false'] - default: false - smoothCount number of matrices to smooth tracking over, more = smoother but slower follow - default: 5 - smoothTolerance distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still - default: 0.01 - smoothThreshold threshold for smoothing, will keep still unless enough matrices are over tolerance - default: 2 - size size of the marker in meter artoolkitmarker.size \u26a1\ufe0f It is suggested to use smooth , smoothCount and smoothTolerance because of weak stabilization of content in Image Tracking. Thanks to smoothing, content is way more stable, from 3D models to 2D videos.","title":"&lt;a-nft\\&gt;"},{"location":"location-based/","text":"","title":"Location Based"},{"location":"marker-based/","text":"Marker Based Markers type Markers are of three, different types: Hiro Barcode Pattern. To learn more about markers, please read this articles: AR.js basic Marker Based tutorial and Markers explanation Deliver AR.js experiences using only QRCodes (Markers inside QRCodes) . How to choose good markers Markers have a black border and high contrast shapes. Lately, we have added also white border markers with black background, altough the classic ones, with black border, behave better. Here's an article explaining all good practice on how to choose good markers, and also images to be used to generate custom markers: 10 tips to enhance your AR.js app . API Reference for Marker Based A-Frame a-marker/ Here are the attributes for this entity Attribute Description Component Mapping type type of marker - ['pattern', 'barcode', 'unknown' ] artoolkitmarker.type size size of the marker in meter artoolkitmarker.size url url of the pattern - IIF type='pattern' artoolkitmarker.patternUrl value value of the barcode - IIF type='barcode' artoolkitmarker.barcodeValue preset parameters preset - ['hiro', 'kanji'] artoolkitmarker.preset emitevents emits 'markerFound' and 'markerLost' events - ['true', 'false'] - smooth turn on/off camera smoothing - ['true', 'false'] - default: false - smoothCount number of matrices to smooth tracking over, more = smoother but slower follow - default: 5 - smoothTolerance distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still - default: 0.01 - smoothThreshold threshold for smoothing, will keep still unless enough matrices are over tolerance - default: 2 - three.js threex-artoolkit threex.artookit is the three.js extension to easily handle artoolkit . It is the main part of my AR.js effort Architecture threex.artoolkit is composed of 3 classes THREEx.ArToolkitSource : It is the image which is analyzed to do the position tracking. It can be the webcam, a video or even an image THREEx.ArToolkitContext : It is the main engine. It will actually find the marker position in the image source. THREEx.ArMarkerControls : it controls the position of the marker It use the classical three.js controls API . It will make sure to position your content right on top of the marker. THREEx.ArMarkerControls var parameters = { // size of the marker in meter size : 1, // type of marker - ['pattern', 'barcode', 'unknown' ] type : 'unknown', // url of the pattern - IIF type='pattern' patternUrl : null, // value of the barcode - IIF type='barcode' barcodeValue : null, // change matrix mode - [modelViewMatrix, cameraTransformMatrix] changeMatrixMode : 'modelViewMatrix', // turn on/off camera smoothing smooth: true, // number of matrices to smooth tracking over, more = smoother but slower follow smoothCount: 5, // distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still smoothTolerance: 0.01, // threshold for smoothing, will keep still unless enough matrices are over tolerance smoothThreshold: 2, } THREEx.ArToolkitContext var parameters = { // debug - true if one should display artoolkit debug canvas, false otherwise debug: false, // the mode of detection - ['color', 'color_and_matrix', 'mono', 'mono_and_matrix'] detectionMode: 'color_and_matrix', // type of matrix code - valid iif detectionMode end with 'matrix' - [3x3, 3x3_HAMMING63, 3x3_PARITY65, 4x4, 4x4_BCH_13_9_3, 4x4_BCH_13_5_5] matrixCodeType: '3x3', // Pattern ratio for custom markers patternRatio: 0.5 // Labeling mode for markers - ['black_region', 'white_region'] // black_region: Black bordered markers on a white background, white_region: White bordered markers on a black background labelingMode: 'black_region', // url of the camera parameters cameraParametersUrl: 'parameters/camera_para.dat', // tune the maximum rate of pose detection in the source image maxDetectionRate: 60, // resolution of at which we detect pose in the source image canvasWidth: 640, canvasHeight: 480, // enable image smoothing or not for canvas copy - default to true // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/imageSmoothingEnabled imageSmoothingEnabled : true, } THREEx.ArToolkitSource var parameters = { // type of source - ['webcam', 'image', 'video'] sourceType : 'webcam', // url of the source - valid if sourceType = image|video sourceUrl : null, // resolution of at which we initialize the source image sourceWidth: 640, sourceHeight: 480, // resolution displayed for the source displayWidth: 640, displayHeight: 480, }","title":"Marker Based"},{"location":"marker-based/#marker-based","text":"","title":"Marker Based"},{"location":"marker-based/#markers-type","text":"Markers are of three, different types: Hiro Barcode Pattern. To learn more about markers, please read this articles: AR.js basic Marker Based tutorial and Markers explanation Deliver AR.js experiences using only QRCodes (Markers inside QRCodes) .","title":"Markers type"},{"location":"marker-based/#how-to-choose-good-markers","text":"Markers have a black border and high contrast shapes. Lately, we have added also white border markers with black background, altough the classic ones, with black border, behave better. Here's an article explaining all good practice on how to choose good markers, and also images to be used to generate custom markers: 10 tips to enhance your AR.js app .","title":"How to choose good markers"},{"location":"marker-based/#api-reference-for-marker-based","text":"","title":"API Reference for Marker Based"},{"location":"marker-based/#a-frame","text":"","title":"A-Frame"},{"location":"marker-based/#lta-markergt","text":"Here are the attributes for this entity Attribute Description Component Mapping type type of marker - ['pattern', 'barcode', 'unknown' ] artoolkitmarker.type size size of the marker in meter artoolkitmarker.size url url of the pattern - IIF type='pattern' artoolkitmarker.patternUrl value value of the barcode - IIF type='barcode' artoolkitmarker.barcodeValue preset parameters preset - ['hiro', 'kanji'] artoolkitmarker.preset emitevents emits 'markerFound' and 'markerLost' events - ['true', 'false'] - smooth turn on/off camera smoothing - ['true', 'false'] - default: false - smoothCount number of matrices to smooth tracking over, more = smoother but slower follow - default: 5 - smoothTolerance distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still - default: 0.01 - smoothThreshold threshold for smoothing, will keep still unless enough matrices are over tolerance - default: 2 -","title":"&lt;a-marker/&gt;"},{"location":"marker-based/#threejs","text":"","title":"three.js"},{"location":"marker-based/#threex-artoolkit","text":"threex.artookit is the three.js extension to easily handle artoolkit . It is the main part of my AR.js effort","title":"threex-artoolkit"},{"location":"marker-based/#architecture","text":"threex.artoolkit is composed of 3 classes THREEx.ArToolkitSource : It is the image which is analyzed to do the position tracking. It can be the webcam, a video or even an image THREEx.ArToolkitContext : It is the main engine. It will actually find the marker position in the image source. THREEx.ArMarkerControls : it controls the position of the marker It use the classical three.js controls API . It will make sure to position your content right on top of the marker.","title":"Architecture"},{"location":"marker-based/#threexarmarkercontrols","text":"var parameters = { // size of the marker in meter size : 1, // type of marker - ['pattern', 'barcode', 'unknown' ] type : 'unknown', // url of the pattern - IIF type='pattern' patternUrl : null, // value of the barcode - IIF type='barcode' barcodeValue : null, // change matrix mode - [modelViewMatrix, cameraTransformMatrix] changeMatrixMode : 'modelViewMatrix', // turn on/off camera smoothing smooth: true, // number of matrices to smooth tracking over, more = smoother but slower follow smoothCount: 5, // distance tolerance for smoothing, if smoothThreshold # of matrices are under tolerance, tracking will stay still smoothTolerance: 0.01, // threshold for smoothing, will keep still unless enough matrices are over tolerance smoothThreshold: 2, }","title":"THREEx.ArMarkerControls"},{"location":"marker-based/#threexartoolkitcontext","text":"var parameters = { // debug - true if one should display artoolkit debug canvas, false otherwise debug: false, // the mode of detection - ['color', 'color_and_matrix', 'mono', 'mono_and_matrix'] detectionMode: 'color_and_matrix', // type of matrix code - valid iif detectionMode end with 'matrix' - [3x3, 3x3_HAMMING63, 3x3_PARITY65, 4x4, 4x4_BCH_13_9_3, 4x4_BCH_13_5_5] matrixCodeType: '3x3', // Pattern ratio for custom markers patternRatio: 0.5 // Labeling mode for markers - ['black_region', 'white_region'] // black_region: Black bordered markers on a white background, white_region: White bordered markers on a black background labelingMode: 'black_region', // url of the camera parameters cameraParametersUrl: 'parameters/camera_para.dat', // tune the maximum rate of pose detection in the source image maxDetectionRate: 60, // resolution of at which we detect pose in the source image canvasWidth: 640, canvasHeight: 480, // enable image smoothing or not for canvas copy - default to true // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/imageSmoothingEnabled imageSmoothingEnabled : true, }","title":"THREEx.ArToolkitContext"},{"location":"marker-based/#threexartoolkitsource","text":"var parameters = { // type of source - ['webcam', 'image', 'video'] sourceType : 'webcam', // url of the source - valid if sourceType = image|video sourceUrl : null, // resolution of at which we initialize the source image sourceWidth: 640, sourceHeight: 480, // resolution displayed for the source displayWidth: 640, displayHeight: 480, }","title":"THREEx.ArToolkitSource"},{"location":"ui-events/","text":"UI and Custom Events To make AR.js based Web App looking better and add UI capabilities, it's possible to treat is as common website. Here you will learn how to use Raycaster, Custom Events and Interaction with overlayed DOM elements. First of all, an introduction about click interactions: it is possible to click directly on content using A-Frame, we tested and had good result with version 0.9.2 . Keep in mind that clicks (or touch interactions) are not very reliable: it can work if you need only few clicks, not very reliable have to click on very few entities on screen clicks work only on the center of the screen, not at the angles, so beware that your entities, to be clicked, should be great enough and not positioned on angles. What I suggest is that you have always to remember that AR.js is Web AR, that means, you can use any DOM elements interactions you want. They work perfectly and most of the times, the Overlayed DOM content interaction is enough for common needs. Handle clicks on AR content We can use click/touch interactions through raycaster, following A-Frame Docs . We can register an event listener for any a-frame entity. So this method works also for Marker Based, Image Tracking and Location Based. We will show it on a Location Based examples, registering the click on a-entity - so the same can be done with a-marker or a-nft . Interaction with Overlayed DOM content You can add interations by adding DOM HTML elements on the body . For example, startinf from this example: !DOCTYPE html html script src= https://aframe.io/releases/1.0.0/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html We can add on the body, outside the a-scene : div class= buttons button class= say-hi-button /button /div Then, we need to add some CSS to absolute positioning the DIV and BUTTON, and also some scripting to listen to click events. You can customize your a-scene or content, like 3D models, play video, and so on. See on A-Frame Docs on how to change entity properties and work with events: https://aframe.io/docs/1.0.0/introduction/javascript-events-dom-apis.html. We will end up with the following code: !DOCTYPE html html script src= https://aframe.io/releases/1.0.0/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script script window.onload = function() { document.querySelector('.say-hi-button').addEventListener('click', function() { // here you can change also a-scene or a-entity properties, like // changing your 3D model source, size, position and so on // or you can just open links, trigger actions... alert('Hi there!'); }) } /script style .buttons { position: absolute; bottom: 0; left: 0; width: 100%; height: 5em; display: flex; justify-content: center; align-items: center; } .say-hi-button { padding: 0.25em; border-radius: 4px; border: none; background: white; color: black; width: 4em; height: 2em; } /style body style= margin : 0px; overflow: hidden; div class= buttons button class= say-hi-button SAY HI! /button /div a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html Custom Events list AR.js triggers several Custom Events. Some of them are general, other are specific for AR Features. Here's the full list.","title":"UI and Events"},{"location":"ui-events/#ui-and-custom-events","text":"To make AR.js based Web App looking better and add UI capabilities, it's possible to treat is as common website. Here you will learn how to use Raycaster, Custom Events and Interaction with overlayed DOM elements. First of all, an introduction about click interactions: it is possible to click directly on content using A-Frame, we tested and had good result with version 0.9.2 . Keep in mind that clicks (or touch interactions) are not very reliable: it can work if you need only few clicks, not very reliable have to click on very few entities on screen clicks work only on the center of the screen, not at the angles, so beware that your entities, to be clicked, should be great enough and not positioned on angles. What I suggest is that you have always to remember that AR.js is Web AR, that means, you can use any DOM elements interactions you want. They work perfectly and most of the times, the Overlayed DOM content interaction is enough for common needs.","title":"UI and Custom Events"},{"location":"ui-events/#handle-clicks-on-ar-content","text":"We can use click/touch interactions through raycaster, following A-Frame Docs . We can register an event listener for any a-frame entity. So this method works also for Marker Based, Image Tracking and Location Based. We will show it on a Location Based examples, registering the click on a-entity - so the same can be done with a-marker or a-nft .","title":"Handle clicks on AR content"},{"location":"ui-events/#interaction-with-overlayed-dom-content","text":"You can add interations by adding DOM HTML elements on the body . For example, startinf from this example: !DOCTYPE html html script src= https://aframe.io/releases/1.0.0/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html We can add on the body, outside the a-scene : div class= buttons button class= say-hi-button /button /div Then, we need to add some CSS to absolute positioning the DIV and BUTTON, and also some scripting to listen to click events. You can customize your a-scene or content, like 3D models, play video, and so on. See on A-Frame Docs on how to change entity properties and work with events: https://aframe.io/docs/1.0.0/introduction/javascript-events-dom-apis.html. We will end up with the following code: !DOCTYPE html html script src= https://aframe.io/releases/1.0.0/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script script window.onload = function() { document.querySelector('.say-hi-button').addEventListener('click', function() { // here you can change also a-scene or a-entity properties, like // changing your 3D model source, size, position and so on // or you can just open links, trigger actions... alert('Hi there!'); }) } /script style .buttons { position: absolute; bottom: 0; left: 0; width: 100%; height: 5em; display: flex; justify-content: center; align-items: center; } .say-hi-button { padding: 0.25em; border-radius: 4px; border: none; background: white; color: black; width: 4em; height: 2em; } /style body style= margin : 0px; overflow: hidden; div class= buttons button class= say-hi-button SAY HI! /button /div a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0 0 scale= 0.05 0.05 0.05 gltf-model= https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html","title":"Interaction with Overlayed DOM content"},{"location":"ui-events/#custom-events-list","text":"AR.js triggers several Custom Events. Some of them are general, other are specific for AR Features. Here's the full list.","title":"Custom Events list"}]}