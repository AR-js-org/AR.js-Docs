{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AR.js - Augmented Reality on the Web AR.js is a lightweight library for Augmented Reality on the Web, coming with features like Image Tracking, Location based AR and Marker tracking. Why AR.js We believe in the Web, a collaborative and accessible place. We also believe in the Augmented Reality technology, as a new communication medium, that can help people to see the reality in new, exciting ways. We see Augmented Reality (AR) used everyday for a lot of useful applications, from art, to education, also for fun. We strongly believe that such a powerful technology, that can help people and leverage their creativity, should be free in some way. Also collaborative, if possible. And so, we continue the work started by Jerome Etienne, in bringing AR on the Web, as a free and Open Source technology. Thank you for being interested in this, if you'd like to collaborate in any way, contact us ( https://twitter.com/nicolocarp ). The project is now under a Github organization, that you can find at https://github.com/ar-js-org and you can ask to be part of it, for free. AR types Ar.js features the following types of Augmented Reality, on the Web: Image Tracking Location Based AR Marker Tracking. Key points Very Fast : It runs efficiently even on phones Web-based : It is a pure web solution, so no installation required. Full javascript based on three.js + A-Frame + jsartoolkit5 Open Source : It is completely open source and free of charge! Standards : It works on any phone with webgl and webrtc AR.js has reached version 3. This is the official repository: https://github.com/AR-js-org/AR.js . If you want to visit the old AR.js repository, here it is: https://github.com/jeromeetienne/AR.js . Import the library AR.js from version 3 has a new structure. AR.js is coming in two, different build. They are both maintained. They are exclusive. The file you want to import depends on what feature you want to have, and also which render library you want to use. AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . You can import AR.js in one version of your choice, using the script tag on your HTML. AR.js with Image Tracking + Location Based AR Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar-nft.js AR.js with Marker Tracking + Location Based AR: Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar.js Requirements Some requirements and known restrictions are listed below: It works on any phone with webgl and webrtc . Marker based is very lightweight, while Image Tracking is more CPU consuming. You cannot use Chrome on iOS, as Chrome on iOS did not support, at the moment, camera access On device with multi-cameras, Chrome may have problems on detecting the right one. Please use Firefox if you find that AR.js opens on the wrong camera. There is an open issue for this. To work with Location Based feature, your phone needs to have GPS sensors. Please, read carefully all suggestions that AR.js pops up for Location Based on iOS, as iOS requires user actions to activate geoposition. Location Based feature is only available on A-Frame Location Based can work with A-Frame up to version 0.9.2. Compatibility with A-Frame v1.0.0 is work in progress. Always deploy under https Accessing to the phone camera or to camera GPS sensors, due to major browsers restrictions, can be done only under https websites. All the examples you will see, and all AR.js web apps in general, have to be run on a server. You can use local server or deploy the static web app on the web. Please, always run your examples on secure connections servers or localhost. Github Pages is a great way to have free and live websites under https. Getting started Here we present three, basic examples, one for each AR feature. For specific documentation, on the top menu you can find every section, or you can click on the following links: Image Tracking Documentation Location Based Documentation Marker Based Documentation Image Tracking Example Please follow this simple steps: Create a new project with the code below (or try this codepen and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded -- div class= arjs-loader div Loading, please wait... /div /div a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors-anywhere proxy to avoid cross-origin problems -- a-nft type= nft url= https://cors-anywhere.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 a-entity gltf-model= https://cors-anywhere.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf scale= 5 5 5 position= 50 150 0 /a-entity /a-nft a-entity camera /a-entity /a-scene /body Location Based Example Please follow this simple steps: Create a new project with the following snippet, and change add-your-latitude and add-your-longitude with your latitude and longitude, without the . Run it on a server Activate GPS on your phone and navigate to the example URL Look around. You should see the text looking at you, appearing in the requested position, even if you look around and move. !DOCTYPE html html head meta charset= utf-8 / meta http-equiv= X-UA-Compatible content= IE=edge / title GeoAR.js demo /title !-- with location based, use aframe v0.9.2 -- script src= https://aframe.io/releases/0.9.2/aframe.min.js /script script src= https://unpkg.com/aframe-look-at-component@0.8.0/dist/aframe-look-at-component.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script /head body style= margin: 0; overflow: hidden; a-scene vr-mode-ui= enabled: false embedded arjs= sourceType: webcam; debugUIEnabled: false; a-text value= This content will always face you. look-at= [gps-camera] scale= 120 120 120 gps-entity-place= latitude: add-your-latitude ; longitude: add-your-longitude ; /a-text a-camera gps-camera rotation-reader /a-camera /a-scene /body /html Marker Based Example Please follow this simple steps: Create a new project with the code below (or try this codepen and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. !DOCTYPE html html script src= https://aframe.io/releases/1.0.0/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0.5 0 gltf-model= https://cors-anywhere.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html","title":"Home"},{"location":"#arjs-augmented-reality-on-the-web","text":"AR.js is a lightweight library for Augmented Reality on the Web, coming with features like Image Tracking, Location based AR and Marker tracking.","title":"AR.js - Augmented Reality on the Web"},{"location":"#why-arjs","text":"We believe in the Web, a collaborative and accessible place. We also believe in the Augmented Reality technology, as a new communication medium, that can help people to see the reality in new, exciting ways. We see Augmented Reality (AR) used everyday for a lot of useful applications, from art, to education, also for fun. We strongly believe that such a powerful technology, that can help people and leverage their creativity, should be free in some way. Also collaborative, if possible. And so, we continue the work started by Jerome Etienne, in bringing AR on the Web, as a free and Open Source technology. Thank you for being interested in this, if you'd like to collaborate in any way, contact us ( https://twitter.com/nicolocarp ). The project is now under a Github organization, that you can find at https://github.com/ar-js-org and you can ask to be part of it, for free.","title":"Why AR.js"},{"location":"#ar-types","text":"Ar.js features the following types of Augmented Reality, on the Web: Image Tracking Location Based AR Marker Tracking.","title":"AR types"},{"location":"#key-points","text":"Very Fast : It runs efficiently even on phones Web-based : It is a pure web solution, so no installation required. Full javascript based on three.js + A-Frame + jsartoolkit5 Open Source : It is completely open source and free of charge! Standards : It works on any phone with webgl and webrtc AR.js has reached version 3. This is the official repository: https://github.com/AR-js-org/AR.js . If you want to visit the old AR.js repository, here it is: https://github.com/jeromeetienne/AR.js .","title":"Key points"},{"location":"#import-the-library","text":"AR.js from version 3 has a new structure. AR.js is coming in two, different build. They are both maintained. They are exclusive. The file you want to import depends on what feature you want to have, and also which render library you want to use. AR.js uses jsartoolkit5 for tracking, but can display augmented content with either three.js or A-Frame . You can import AR.js in one version of your choice, using the script tag on your HTML. AR.js with Image Tracking + Location Based AR Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar-nft.js AR.js with Marker Tracking + Location Based AR: Import AFRAME version: script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js Import three.js version: script src= https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar.js","title":"Import the library"},{"location":"#requirements","text":"Some requirements and known restrictions are listed below: It works on any phone with webgl and webrtc . Marker based is very lightweight, while Image Tracking is more CPU consuming. You cannot use Chrome on iOS, as Chrome on iOS did not support, at the moment, camera access On device with multi-cameras, Chrome may have problems on detecting the right one. Please use Firefox if you find that AR.js opens on the wrong camera. There is an open issue for this. To work with Location Based feature, your phone needs to have GPS sensors. Please, read carefully all suggestions that AR.js pops up for Location Based on iOS, as iOS requires user actions to activate geoposition. Location Based feature is only available on A-Frame Location Based can work with A-Frame up to version 0.9.2. Compatibility with A-Frame v1.0.0 is work in progress.","title":"Requirements"},{"location":"#always-deploy-under-https","text":"Accessing to the phone camera or to camera GPS sensors, due to major browsers restrictions, can be done only under https websites. All the examples you will see, and all AR.js web apps in general, have to be run on a server. You can use local server or deploy the static web app on the web. Please, always run your examples on secure connections servers or localhost. Github Pages is a great way to have free and live websites under https.","title":"Always deploy under https"},{"location":"#getting-started","text":"Here we present three, basic examples, one for each AR feature. For specific documentation, on the top menu you can find every section, or you can click on the following links: Image Tracking Documentation Location Based Documentation Marker Based Documentation","title":"Getting started"},{"location":"#image-tracking-example","text":"Please follow this simple steps: Create a new project with the code below (or try this codepen and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. script src= https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script style .arjs-loader { height: 100%; width: 100%; position: absolute; top: 0; left: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 9999; display: flex; justify-content: center; align-items: center; } .arjs-loader div { text-align: center; font-size: 1.25em; color: white; } /style body style= margin : 0px; overflow: hidden; !-- minimal loader shown until image descriptors are loaded -- div class= arjs-loader div Loading, please wait... /div /div a-scene vr-mode-ui= enabled: false; renderer= logarithmicDepthBuffer: true; embedded arjs= trackingMethod: best; sourceType: webcam;debugUIEnabled: false; !-- we use cors-anywhere proxy to avoid cross-origin problems -- a-nft type= nft url= https://cors-anywhere.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex smooth= true smoothCount= 10 smoothTolerance= .01 smoothThreshold= 5 a-entity gltf-model= https://cors-anywhere.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf scale= 5 5 5 position= 50 150 0 /a-entity /a-nft a-entity camera /a-entity /a-scene /body","title":"Image Tracking Example"},{"location":"#location-based-example","text":"Please follow this simple steps: Create a new project with the following snippet, and change add-your-latitude and add-your-longitude with your latitude and longitude, without the . Run it on a server Activate GPS on your phone and navigate to the example URL Look around. You should see the text looking at you, appearing in the requested position, even if you look around and move. !DOCTYPE html html head meta charset= utf-8 / meta http-equiv= X-UA-Compatible content= IE=edge / title GeoAR.js demo /title !-- with location based, use aframe v0.9.2 -- script src= https://aframe.io/releases/0.9.2/aframe.min.js /script script src= https://unpkg.com/aframe-look-at-component@0.8.0/dist/aframe-look-at-component.min.js /script script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js /script /head body style= margin: 0; overflow: hidden; a-scene vr-mode-ui= enabled: false embedded arjs= sourceType: webcam; debugUIEnabled: false; a-text value= This content will always face you. look-at= [gps-camera] scale= 120 120 120 gps-entity-place= latitude: add-your-latitude ; longitude: add-your-longitude ; /a-text a-camera gps-camera rotation-reader /a-camera /a-scene /body /html","title":"Location Based Example"},{"location":"#marker-based-example","text":"Please follow this simple steps: Create a new project with the code below (or try this codepen and go directly to the last step) Run it on a server Open the website on your phone Scan this picture to see content through the camera. !DOCTYPE html html script src= https://aframe.io/releases/1.0.0/aframe.min.js /script !-- we import arjs version without NFT but with marker + location based support -- script src= https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js /script body style= margin : 0px; overflow: hidden; a-scene embedded arjs a-marker preset= hiro a-entity position= 0 0.5 0 gltf-model= https://cors-anywhere.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf /a-entity /a-marker a-entity camera /a-entity /a-scene /body /html","title":"Marker Based Example"},{"location":"about/","text":"This project has been created by @jeromeetienne and it is now maintained by @nicolocarpignoli . For frequent updates on AR.js you can follow @nicolocarp and Watch this repo! After months of work, we have changed AR.js for good. The aim was to make it a true, free alternative to paid Web AR solutions. We don't know if we're already there, but now the path is clear, at least. We have worked hard, spent many days and nights\u200a-\u200aobviously, we are coders, what did you expect?\u200a-\u200aand we are now so thrilled to share this achievement with the community. We know that it can be better, we know its limitations, but we would love to share this journey's result. AR.js is now under a Github organisation, that means, more collaborative than ever. It has a new structure, and a lot of new code. And most of all, we've added Image Tracking, what we felt was the missing piece for a true alternative to Web AR. A huge, huge thanks to the wonderful guys who made this possible: Walter Perdan Thorsten Bux Daniel Fernandes misdake hatsumatsu and many more. It was great to built this with all of you.","title":"About"},{"location":"image-tracking/","text":"Image Tracking Image Tracking makes possible to scan a picture, drawing, any image, and show content over it. All the following examples are with A-Frame, for semplicity. You can use three.js if you want. See on the official repository the three.js examples , search for 'nft' example. All A-Frame examples for Image Tracking can be found here . Getting started with Image Tracking Thanks to Daniel Fernandes for contribution on this docs section. Natural Feature Tracking or NFT is a technology that enables the use of images instead of markers like QR Codes or the Hiro. Now you can use any image you want! The software tracks interesting points in the image and from that it estimates the position of the camera. These interesting points (aka \"Image Descriptors\") are created using the NFT Marker Creator , a tool available to you for creating NFT markers, it has two versions the WEB APP (recommended), and the NODE APP . There is also a fork on the AR.js Github organisation, but as for now, Daniel Fernandes version works perfectly. Choose good images If you want to understand the creation of markers in more depth, check out the NFT Marker Creator wiki . Create Image Descriptors Once you have chosen your image, you can either use the web version or the node version. If you're using the node version, this is the basic command to run: node app.js -i path-to-the-img/image-name.jpg/png And you will find the Image Descriptors files on the output folder. In the web version, the generator will automatically download the files from your browser. In either cases, you will end up with three files as Image Descriptors, with .fset , .fset3 , .iset . Each of them will have the same prefix before the file extension. That one will be the Image Descriptor name that you will use on the AR.js web app. Render the content Now it's time to create the actual Web app.","title":"Image Tracking"},{"location":"image-tracking/#image-tracking","text":"Image Tracking makes possible to scan a picture, drawing, any image, and show content over it. All the following examples are with A-Frame, for semplicity. You can use three.js if you want. See on the official repository the three.js examples , search for 'nft' example. All A-Frame examples for Image Tracking can be found here .","title":"Image Tracking"},{"location":"image-tracking/#getting-started-with-image-tracking","text":"Thanks to Daniel Fernandes for contribution on this docs section. Natural Feature Tracking or NFT is a technology that enables the use of images instead of markers like QR Codes or the Hiro. Now you can use any image you want! The software tracks interesting points in the image and from that it estimates the position of the camera. These interesting points (aka \"Image Descriptors\") are created using the NFT Marker Creator , a tool available to you for creating NFT markers, it has two versions the WEB APP (recommended), and the NODE APP . There is also a fork on the AR.js Github organisation, but as for now, Daniel Fernandes version works perfectly.","title":"Getting started with Image Tracking"},{"location":"image-tracking/#choose-good-images","text":"If you want to understand the creation of markers in more depth, check out the NFT Marker Creator wiki .","title":"Choose good images"},{"location":"image-tracking/#create-image-descriptors","text":"Once you have chosen your image, you can either use the web version or the node version. If you're using the node version, this is the basic command to run: node app.js -i path-to-the-img/image-name.jpg/png And you will find the Image Descriptors files on the output folder. In the web version, the generator will automatically download the files from your browser. In either cases, you will end up with three files as Image Descriptors, with .fset , .fset3 , .iset . Each of them will have the same prefix before the file extension. That one will be the Image Descriptor name that you will use on the AR.js web app.","title":"Create Image Descriptors"},{"location":"image-tracking/#render-the-content","text":"Now it's time to create the actual Web app.","title":"Render the content"},{"location":"location-based/","text":"","title":"Location Based"},{"location":"marker-based/","text":"","title":"Marker Based"},{"location":"tools/","text":"","title":"Tools"}]}